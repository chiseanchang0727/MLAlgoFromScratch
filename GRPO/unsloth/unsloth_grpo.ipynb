{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884dc606",
   "metadata": {},
   "source": [
    "- Ref: https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb#scrollTo=DkIvEkIIkEyB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b9ec6",
   "metadata": {},
   "source": [
    "Instal unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac4576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "# uv add \"unsloth[cu124-torch251] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db15e63",
   "metadata": {},
   "source": [
    "Pre-fine-tune the model to make GRPO follow the desired output format — this speeds up GRPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7052ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/MLAlgoFromScratch/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 08-26 09:03:06 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 08-26 09:03:06 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 09:03:08,403\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bb6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fdbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb056b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Patching vLLM v1 graph capture\n",
      "Unsloth: Patching vLLM v0 graph capture\n",
      "==((====))==  Unsloth 2025.7.8: Fast Qwen3 patching. Transformers: 4.54.0. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.581 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen3-4b-base-unsloth-bnb-4bit with actual GPU utilization = 59.0%\n",
      "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.58 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 512. Num Sequences = 192.\n",
      "Unsloth: vLLM's KV Cache can use up to 5.94 GB. Also swap space = 0 GB.\n",
      "WARNING 08-26 09:03:23 [config.py:2972] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 08-26 09:03:34 [config.py:717] This model supports multiple tasks: {'score', 'embed', 'reward', 'classify', 'generate'}. Defaulting to 'generate'.\n",
      "WARNING 08-26 09:03:34 [arg_utils.py:1658] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.0.mlp', 'model.layers.4.mlp', 'model.layers.3.self_attn', 'model.layers.0.self_attn', 'model.layers.6.mlp', 'model.layers.1.self_attn', 'model.layers.1.mlp', 'model.layers.2.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 08-26 09:03:34 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='unsloth/qwen3-4b-base-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen3-4b-base-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=512, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen3-4b-base-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"backend\":\"inductor\",\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":true,\"trace.graph_diagram\":false,\"compile_threads\":4,\"combo_kernels\":false,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":true,\"enable_auto_functionalized_v2\":false},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":192}, use_cached_outputs=False, \n",
      "INFO 08-26 09:03:37 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 08-26 09:03:37 [cuda.py:289] Using XFormers backend.\n",
      "INFO 08-26 09:03:37 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 08-26 09:03:37 [model_runner.py:1108] Starting to load model unsloth/qwen3-4b-base-unsloth-bnb-4bit...\n",
      "INFO 08-26 09:03:37 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 08-26 09:03:40 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 08-26 09:03:40 [weight_utils.py:281] Time spent downloading weights for unsloth/qwen3-4b-base-unsloth-bnb-4bit: 0.700147 seconds\n",
      "INFO 08-26 09:03:41 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:13<00:00, 13.26s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:13<00:00, 13.26s/it]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.44s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-26 09:03:56 [punica_selector.py:18] Using PunicaWrapperGPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-26 09:03:56 [model_runner.py:1140] Model loading took 3.1446 GiB and 18.560822 seconds\n",
      "INFO 08-26 09:04:00 [worker.py:287] Memory profiling takes 3.77 seconds\n",
      "INFO 08-26 09:04:00 [worker.py:287] the current vLLM instance can use total_gpu_memory (14.58GiB) x gpu_memory_utilization (0.59) = 8.60GiB\n",
      "INFO 08-26 09:04:00 [worker.py:287] model weights take 3.14GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 4.39GiB.\n",
      "INFO 08-26 09:04:01 [executor_base.py:112] # cuda blocks: 1995, # CPU blocks: 0\n",
      "INFO 08-26 09:04:01 [executor_base.py:117] Maximum concurrency for 512 tokens per request: 62.34x\n",
      "INFO 08-26 09:04:01 [vllm_utils.py:669] Unsloth: Running patched vLLM v0 `capture_model`.\n",
      "INFO 08-26 09:04:01 [model_runner.py:1450] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 27/27 [00:13<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-26 09:04:14 [model_runner.py:1592] Graph capturing finished in 14 secs, took 4.24 GiB\n",
      "INFO 08-26 09:04:14 [vllm_utils.py:676] Unsloth: Patched vLLM v0 graph capture finished in 14 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-26 09:04:15 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 19.00 seconds\n",
      "Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'post_feedforward_layernorm']\n",
      "Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'post_feedforward_layernorm']\n"
     ]
    }
   ],
   "source": [
    "# key: vllm==0.8.5.post1\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name='unsloth/Qwen3-4B-base',\n",
    "    max_seq_length=512,\n",
    "    load_in_4bit=True,\n",
    "    fast_inference=True, # Enable vLLM fast inference\n",
    "    max_lora_rank=8,\n",
    "    gpu_memory_utilization=0.6 # Reduce if OOM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa61c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer can handle up to 32768 tokens.\n"
     ]
    }
   ],
   "source": [
    "max_dim = tokenizer.model_max_length\n",
    "print(f\"Tokenizer can handle up to {max_dim} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67cd7872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template is None\n",
    "# ValueError: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37a0c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "      (2): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "      (3): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "      (4): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "      (5): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "      (6): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "      (7-35): 29 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b42afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.7.8 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "lora_rank = 8  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bc681be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3ForCausalLM(\n",
       "      (model): Qwen3Model(\n",
       "        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (2): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (3): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (4): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (5): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (6): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (7-35): 29 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53675cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_start = \"<start_working_out>\" # Acts as <think>\n",
    "reasoning_end   = \"<end_working_out>\"   # Acts as </think>\n",
    "solution_start  = \"<SOLUTION>\"\n",
    "solution_end    = \"</SOLUTION>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"You are given a problem.\n",
    "Think about the problem and provide your working out.\n",
    "Place it between {reasoning_start} and {reasoning_end}.\n",
    "Then, provide your solution between {solution_start}{solution_end}\"\"\"\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5780a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Always includes a system prompt (either from messages or a default one).\n",
    "- Marks assistant turns with an eos_token so the model knows where each reply ends.\n",
    "- Optionally adds a “start reasoning” marker to signal when the model should generate output.\n",
    "- Uses placeholders that get replaced at runtime so you can change system prompts or special tokens without editing the Jinja template.\n",
    "\"\"\"\n",
    "\n",
    "chat_template = \\\n",
    "    \"{% if messages[0]['role'] == 'system' %}\"\\\n",
    "        \"{{ messages[0]['content'] + eos_token }}\"\\\n",
    "        \"{% set loop_messages = messages[1:] %}\"\\\n",
    "    \"{% else %}\"\\\n",
    "        \"{{ '{system_prompt}' + eos_token }}\"\\\n",
    "        \"{% set loop_messages = messages %}\"\\\n",
    "    \"{% endif %}\"\\\n",
    "    \"{% for message in loop_messages %}\"\\\n",
    "        \"{% if message['role'] == 'user' %}\"\\\n",
    "            \"{{ message['content'] }}\"\\\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\\\n",
    "            \"{{ message['content'] + eos_token }}\"\\\n",
    "        \"{% endif %}\"\\\n",
    "    \"{% endfor %}\"\\\n",
    "    \"{% if add_generation_prompt %}{{ '{reasoning_start}' }}\"\\\n",
    "    \"{% endif %}\"\n",
    "\n",
    "# Replace without specific template:\n",
    "chat_template = chat_template\\\n",
    "    .replace(\"'{system_prompt}'\",   f\"'{system_prompt}'\")\\\n",
    "    .replace(\"'{reasoning_start}'\", f\"'{reasoning_start}'\")\n",
    "tokenizer.chat_template = chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7198ff89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|endoftext|>What is 1+1?<start_working_out>I think it's 2.<end_working_out><SOLUTION>2</SOLUTION><|endoftext|>What is 2+2?<start_working_out>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn a structured list of messages into the exact string prompt the model will see.\n",
    "tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"user\", \"content\" : \"What is 1+1?\"},\n",
    "    {\"role\" : \"assistant\", \"content\" : f\"{reasoning_start}I think it's 2.{reasoning_end}{solution_start}2{solution_end}\"},\n",
    "    {\"role\" : \"user\", \"content\" : \"What is 2+2?\"},\n",
    "], tokenize = False, add_generation_prompt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "474d6e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>problem_type</th>\n",
       "      <th>problem_source</th>\n",
       "      <th>generation_model</th>\n",
       "      <th>pass_rate_72b_tir</th>\n",
       "      <th>problem</th>\n",
       "      <th>generated_solution</th>\n",
       "      <th>inference_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c4_high_school_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. I need to solve the ...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convergent</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c7_college_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Let \\( \\sum a_n \\) be a convergent series with...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I have this problem here whe...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\(\\frac{\\pi \\ln a}{2a}\\)</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c7_college_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>For \\( a &gt; 0 \\), find the value of \\( \\int_0^{...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to solve the integral...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\(+\\infty\\)</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c7_college_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Calculate $\\lim_{n\\to\\infty}\\sqrt[n]{n!}$.</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to find the limit as ...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\( n = 1 \\)</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c6_high_school_olympiads</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Find all positive integers \\( n \\) such that \\...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to find all positive ...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>4</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c4_high_school_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>A bus left point X for point Y. Two hours late...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's tackle this problem step ...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19248</th>\n",
       "      <td>18</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c4_high_school_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Each interior angle of a regular n-gon measure...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. I need to find the n...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19249</th>\n",
       "      <td>\\( e^3 - 1 \\)</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c7_college_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Evaluate the series \\( \\sum_{k=1}^{\\infty}\\fra...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to evaluate the serie...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19250</th>\n",
       "      <td>0.8960</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c4_high_school_math</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Find the probability that the second blue resu...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to find the probabili...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>\\( x = 1, y = -1, z = 2 \\)</td>\n",
       "      <td>has_answer_extracted</td>\n",
       "      <td>aops_c6_high_school_olympiads</td>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>Solve the system of equations:\\n\\[ x^2 + y^2 +...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I've got this system of thre...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19252 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  expected_answer          problem_type  \\\n",
       "0                              14  has_answer_extracted   \n",
       "1                      convergent  has_answer_extracted   \n",
       "2        \\(\\frac{\\pi \\ln a}{2a}\\)  has_answer_extracted   \n",
       "3                     \\(+\\infty\\)  has_answer_extracted   \n",
       "4                     \\( n = 1 \\)  has_answer_extracted   \n",
       "...                           ...                   ...   \n",
       "19247                           4  has_answer_extracted   \n",
       "19248                          18  has_answer_extracted   \n",
       "19249               \\( e^3 - 1 \\)  has_answer_extracted   \n",
       "19250                      0.8960  has_answer_extracted   \n",
       "19251  \\( x = 1, y = -1, z = 2 \\)  has_answer_extracted   \n",
       "\n",
       "                      problem_source generation_model pass_rate_72b_tir  \\\n",
       "0           aops_c4_high_school_math      DeepSeek-R1           0.96875   \n",
       "1               aops_c7_college_math      DeepSeek-R1           0.96875   \n",
       "2               aops_c7_college_math      DeepSeek-R1           0.96875   \n",
       "3               aops_c7_college_math      DeepSeek-R1           0.96875   \n",
       "4      aops_c6_high_school_olympiads      DeepSeek-R1           0.96875   \n",
       "...                              ...              ...               ...   \n",
       "19247       aops_c4_high_school_math      DeepSeek-R1           0.96875   \n",
       "19248       aops_c4_high_school_math      DeepSeek-R1           0.96875   \n",
       "19249           aops_c7_college_math      DeepSeek-R1           0.96875   \n",
       "19250       aops_c4_high_school_math      DeepSeek-R1           0.96875   \n",
       "19251  aops_c6_high_school_olympiads      DeepSeek-R1           0.96875   \n",
       "\n",
       "                                                 problem  \\\n",
       "0      Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...   \n",
       "1      Let \\( \\sum a_n \\) be a convergent series with...   \n",
       "2      For \\( a > 0 \\), find the value of \\( \\int_0^{...   \n",
       "3             Calculate $\\lim_{n\\to\\infty}\\sqrt[n]{n!}$.   \n",
       "4      Find all positive integers \\( n \\) such that \\...   \n",
       "...                                                  ...   \n",
       "19247  A bus left point X for point Y. Two hours late...   \n",
       "19248  Each interior angle of a regular n-gon measure...   \n",
       "19249  Evaluate the series \\( \\sum_{k=1}^{\\infty}\\fra...   \n",
       "19250  Find the probability that the second blue resu...   \n",
       "19251  Solve the system of equations:\\n\\[ x^2 + y^2 +...   \n",
       "\n",
       "                                      generated_solution inference_mode  \n",
       "0      <think>\\nOkay, let's see. I need to solve the ...            cot  \n",
       "1      <think>\\nOkay, so I have this problem here whe...            cot  \n",
       "2      <think>\\nOkay, so I need to solve the integral...            cot  \n",
       "3      <think>\\nOkay, so I need to find the limit as ...            cot  \n",
       "4      <think>\\nOkay, so I need to find all positive ...            cot  \n",
       "...                                                  ...            ...  \n",
       "19247  <think>\\nOkay, let's tackle this problem step ...            cot  \n",
       "19248  <think>\\nOkay, let's see. I need to find the n...            cot  \n",
       "19249  <think>\\nOkay, so I need to evaluate the serie...            cot  \n",
       "19250  <think>\\nOkay, so I need to find the probabili...            cot  \n",
       "19251  <think>\\nOkay, so I've got this system of thre...            cot  \n",
       "\n",
       "[19252 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"unsloth/OpenMathReasoning-mini\", split = \"cot\")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "140ef8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:2]\n",
    "dataset = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d4ea3",
   "metadata": {},
   "source": [
    "Note\n",
    "- I think the reason of using math here is the answer is precise\n",
    "- If the result is text, we may compute the text similarity to confirm the answer ?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b36bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.to_pandas()[\n",
    "    [\"expected_answer\", \"problem\", \"generated_solution\"]\n",
    "]\n",
    "\n",
    "# Try converting to number - if not, replace with NaN\n",
    "is_number = pd.to_numeric(pd.Series(dataset[\"expected_answer\"]), errors = \"coerce\").notnull()\n",
    "# Select only numbers\n",
    "dataset = dataset.iloc[np.where(is_number)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7deb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(x):\n",
    "    expected_answer = x[\"expected_answer\"]\n",
    "    problem = x[\"problem\"]\n",
    "\n",
    "    # Remove generated <think> and </think>\n",
    "    thoughts = x[\"generated_solution\"]\n",
    "    thoughts = thoughts.replace(\"<think>\", \"\").replace(\"</think>\", \"\")\n",
    "\n",
    "    # Strip newlines on left and right\n",
    "    thoughts = thoughts.strip()\n",
    "    # Add our custom formatting\n",
    "    final_prompt = \\\n",
    "        reasoning_start + thoughts + reasoning_end + \\\n",
    "        solution_start + expected_answer + solution_end\n",
    "    return [\n",
    "        {\"role\" : \"system\",    \"content\" : system_prompt},\n",
    "        {\"role\" : \"user\",      \"content\" : problem},\n",
    "        {\"role\" : \"assistant\", \"content\" : final_prompt},\n",
    "    ]\n",
    "\n",
    "dataset[\"Messages\"] = dataset.apply(format_dataset, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "532c1aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION>'},\n",
       " {'role': 'user',\n",
       "  'content': 'Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"<start_working_out>Okay, let's see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n√(x² + 165) - √(x² - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n√(x² + 165) = 7 + √(x² - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(√(x² + 165))² = (7 + √(x² - 52))².\\n\\nSimplifying the left side:\\n\\nx² + 165 = 49 + 14√(x² - 52) + (√(x² - 52))².\\n\\nThe right side is expanded using the formula (a + b)² = a² + 2ab + b². So the right side becomes 7² + 2*7*√(x² - 52) + (√(x² - 52))², which is 49 + 14√(x² - 52) + (x² - 52).\\n\\nSo putting it all together:\\n\\nx² + 165 = 49 + 14√(x² - 52) + x² - 52.\\n\\nHmm, let's simplify the right side. The x² terms will cancel out, right? Let's subtract x² from both sides:\\n\\n165 = 49 + 14√(x² - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14√(x² - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14√(x² - 52).\\n\\nSo 168 = 14√(x² - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = √(x² - 52).\\n\\n12 = √(x² - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12² = x² - 52.\\n\\n144 = x² - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x².\\n\\n196 = x².\\n\\nSo x = √196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n√(14² + 165) - √(14² - 52) = ?\\n\\nCalculate each term:\\n\\n14² is 196.\\n\\nSo first radical: √(196 + 165) = √361 = 19.\\n\\nSecond radical: √(196 - 52) = √144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\nTo solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]<end_working_out><SOLUTION>14</SOLUTION>\"}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msg = dataset.iloc[0].Messages\n",
    "test_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bce393",
   "metadata": {},
   "source": [
    "Check to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc0e4022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|endoftext|>Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.<start_working_out>Okay, let's see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, and find all positive values of x. Hmm, radicals can be tricky, but maybe if I can eliminate the square roots by squaring both sides. Let me try that.\\n\\nFirst, let me write down the equation again to make sure I have it right:\\n\\n√(x² + 165) - √(x² - 52) = 7.\\n\\nOkay, so the idea is to isolate one of the radicals and then square both sides. Let me try moving the second radical to the other side:\\n\\n√(x² + 165) = 7 + √(x² - 52).\\n\\nNow, if I square both sides, maybe I can get rid of the square roots. Let's do that:\\n\\n(√(x² + 165))² = (7 + √(x² - 52))².\\n\\nSimplifying the left side:\\n\\nx² + 165 = 49 + 14√(x² - 52) + (√(x² - 52))².\\n\\nThe right side is expanded using the formula (a + b)² = a² + 2ab + b². So the right side becomes 7² + 2*7*√(x² - 52) + (√(x² - 52))², which is 49 + 14√(x² - 52) + (x² - 52).\\n\\nSo putting it all together:\\n\\nx² + 165 = 49 + 14√(x² - 52) + x² - 52.\\n\\nHmm, let's simplify the right side. The x² terms will cancel out, right? Let's subtract x² from both sides:\\n\\n165 = 49 + 14√(x² - 52) - 52.\\n\\nSimplify the constants on the right:\\n\\n49 - 52 is -3, so:\\n\\n165 = -3 + 14√(x² - 52).\\n\\nNow, add 3 to both sides to isolate the radical term:\\n\\n165 + 3 = 14√(x² - 52).\\n\\nSo 168 = 14√(x² - 52).\\n\\nDivide both sides by 14:\\n\\n168 / 14 = √(x² - 52).\\n\\n12 = √(x² - 52).\\n\\nNow, square both sides again to eliminate the square root:\\n\\n12² = x² - 52.\\n\\n144 = x² - 52.\\n\\nAdd 52 to both sides:\\n\\n144 + 52 = x².\\n\\n196 = x².\\n\\nSo x = √196 = 14.\\n\\nBut wait, since the problem states that x is positive, we only take the positive root. So x = 14.\\n\\nBut hold on, when dealing with squaring equations, sometimes extraneous solutions can come up. I should check if this solution actually satisfies the original equation.\\n\\nLet's plug x = 14 back into the original equation:\\n\\n√(14² + 165) - √(14² - 52) = ?\\n\\nCalculate each term:\\n\\n14² is 196.\\n\\nSo first radical: √(196 + 165) = √361 = 19.\\n\\nSecond radical: √(196 - 52) = √144 = 12.\\n\\nSo 19 - 12 = 7, which is exactly the right-hand side. So yes, it checks out.\\n\\nTherefore, the only solution is x = 14. Since the problem says x is positive, we don't have to consider negative roots. So I think that's the answer.\\nTo solve the equation \\\\(\\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\\\) for positive \\\\(x\\\\), we proceed as follows:\\n\\n1. Start with the given equation:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} - \\\\sqrt{x^2 - 52} = 7\\n   \\\\]\\n\\n2. Isolate one of the square roots by moving \\\\(\\\\sqrt{x^2 - 52}\\\\) to the right side:\\n   \\\\[\\n   \\\\sqrt{x^2 + 165} = 7 + \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n3. Square both sides to eliminate the square root on the left:\\n   \\\\[\\n   (\\\\sqrt{x^2 + 165})^2 = (7 + \\\\sqrt{x^2 - 52})^2\\n   \\\\]\\n   Simplifying both sides, we get:\\n   \\\\[\\n   x^2 + 165 = 49 + 14\\\\sqrt{x^2 - 52} + (x^2 - 52)\\n   \\\\]\\n\\n4. Combine like terms on the right side:\\n   \\\\[\\n   x^2 + 165 = x^2 - 52 + 49 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n   Simplifying further:\\n   \\\\[\\n   x^2 + 165 = x^2 - 3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n5. Subtract \\\\(x^2\\\\) from both sides:\\n   \\\\[\\n   165 = -3 + 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n6. Add 3 to both sides to isolate the term with the square root:\\n   \\\\[\\n   168 = 14\\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n7. Divide both sides by 14:\\n   \\\\[\\n   12 = \\\\sqrt{x^2 - 52}\\n   \\\\]\\n\\n8. Square both sides again to eliminate the square root:\\n   \\\\[\\n   12^2 = x^2 - 52\\n   \\\\]\\n   Simplifying:\\n   \\\\[\\n   144 = x^2 - 52\\n   \\\\]\\n\\n9. Add 52 to both sides to solve for \\\\(x^2\\\\):\\n   \\\\[\\n   196 = x^2\\n   \\\\]\\n\\n10. Take the positive square root (since \\\\(x\\\\) is positive):\\n    \\\\[\\n    x = \\\\sqrt{196} = 14\\n    \\\\]\\n\\n11. Verify the solution by substituting \\\\(x = 14\\\\) back into the original equation:\\n    \\\\[\\n    \\\\sqrt{14^2 + 165} - \\\\sqrt{14^2 - 52} = \\\\sqrt{196 + 165} - \\\\sqrt{196 - 52} = \\\\sqrt{361} - \\\\sqrt{144} = 19 - 12 = 7\\n    \\\\]\\n    The solution checks out.\\n\\nThus, the only positive solution is:\\n\\\\[\\n\\\\boxed{14}\\n\\\\]<end_working_out><SOLUTION>14</SOLUTION><|endoftext|>\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default of tokenize is True\n",
    "tokenizer.apply_chat_template(test_msg, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4d2bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized result: [2610, 525, 2661, 264, 3491, 624, 38687, 911, 279, 3491]... \n",
      "with dimension: 1682\n"
     ]
    }
   ],
   "source": [
    "tokenized_result = tokenizer.apply_chat_template(test_msg)\n",
    "print(f\"Tokenized result: {tokenized_result[:10]}... \\nwith dimension: {len(tokenized_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81920244",
   "metadata": {},
   "source": [
    "Limit sequence length to max_seq_length / 2 during pre-fine-tuning to avoid overly long reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "769dbb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.loc[[len(tokenizer.apply_chat_template(x)) < max_seq_length for x in dataset['Messages']]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb5ae3",
   "metadata": {},
   "source": [
    "Tokenize data and convert it to a HF compatible dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3d0e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = tokenizer.apply_chat_template(dataset['Messages'].values.tolist(), tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9aaeabe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>problem</th>\n",
       "      <th>generated_solution</th>\n",
       "      <th>Messages</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. I need to solve the ...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are given ...</td>\n",
       "      <td>You are given a problem.\\nThink about the prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>Find the value of the parameter $a$ for which ...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to find the value of ...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are given ...</td>\n",
       "      <td>You are given a problem.\\nThink about the prob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  expected_answer                                            problem  \\\n",
       "0              14  Given $\\sqrt{x^2+165}-\\sqrt{x^2-52}=7$ and $x$...   \n",
       "1              -2  Find the value of the parameter $a$ for which ...   \n",
       "\n",
       "                                  generated_solution  \\\n",
       "0  <think>\\nOkay, let's see. I need to solve the ...   \n",
       "1  <think>\\nOkay, so I need to find the value of ...   \n",
       "\n",
       "                                            Messages  \\\n",
       "0  [{'role': 'system', 'content': 'You are given ...   \n",
       "1  [{'role': 'system', 'content': 'You are given ...   \n",
       "\n",
       "                                                text  \n",
       "0  You are given a problem.\\nThink about the prob...  \n",
       "1  You are given a problem.\\nThink about the prob...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f177fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e4ca959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['expected_answer', 'problem', 'generated_solution', 'Messages', 'text', '__index_level_0__'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b6ef3",
   "metadata": {},
   "source": [
    "Pre fine-tune the model so it follows the custom GRPO formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.68s/it, est. speed input: 1.03 toks/s, output: 28.41 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Quora\n",
      "What is the sqrt of 101?\n",
      "6 Answers\n",
      "Best\n",
      "Gaurav Bakliwal\n",
      "Answered 2 years ago · Author has 526 answers and 384.9K answer author has 20.8K answers and 10M answer views 2 y\n",
      "What is the sqrt of 101?\n",
      "First of all 101 is not a square. It is pretty close to 100 which is 10×10. However 101 is 4 more than 100, so take √(100+4)\n",
      "=(√100)+√4\n",
      "=10 + 2\n",
      "100.50.00.25.00…\n",
      "√101 =10.05\n",
      "Related\n",
      "What is the square root of 614? (in square root symbol)\n",
      "What is the square root of 614? (in square root symbol)\n",
      "2,08.8\n",
      "614 = 4 *153.5\n",
      "2,√153.5\n",
      "614 is a prime number.\n",
      "Related Question\n",
      "What is the square root of 614? (in squared symbol)\n",
      "2,20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check the result before pre fine-tune\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 1.0,\n",
    "    top_k = 50,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "text = \"What is the sqrt of 101?\"\n",
    "output = model.fast_generate(\n",
    "    [text], \n",
    "    sampling_params=sampling_params, \n",
    "    lora_request=None\n",
    ")\n",
    "print(output[0].outputs[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "423bd757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|██████████| 2/2 [00:01<00:00,  1.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field='text',\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8, # update after accumulation step\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=2,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=5,\n",
    "        optim='adamw_8bit',\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type='linear',\n",
    "        seed=3407,\n",
    "        report_to='none'\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bda30c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2 | Num Epochs = 2 | Total steps = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 16,515,072 of 4,038,983,168 (0.41% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=0.864276647567749, metrics={'train_runtime': 4.9164, 'train_samples_per_second': 0.814, 'train_steps_per_second': 0.407, 'total_flos': 25306746322944.0, 'train_loss': 0.864276647567749})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52678b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <start_working_out> and <end_working_out>.\\nThen, provide your solution between <SOLUTION></SOLUTION><|endoftext|>Given $\\\\sqrt{x^2+165}-\\\\sqrt{x^2-52}=7$ and $x$ is positive, find all possible values of $x$.<start_working_out>'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    dataset[0][\"Messages\"][:2],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True # add this then the ending is \"<start_working_out>\"\n",
    ")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ee5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TextStreamer\n",
    "# _ = model.generate(\n",
    "#     **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "#     temperature = 0,\n",
    "#     max_new_tokens = 1024,\n",
    "#     streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "609db5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean memory\n",
    "del dataset\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5288ea27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'solution', 'data_source', 'source_prompt', 'ability', 'reward_model', 'extra_info'],\n",
       "    num_rows: 14116\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"open-r1/DAPO-Math-17k-Processed\", \"en\", split = \"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84efda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc61606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "911a89ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Solve the following math problem step by step. The last line of your response should be of the form Answer: $Answer (without quotes) where $Answer is the answer to the problem.\\n\\nIn triangle $ABC$, $\\\\sin \\\\angle A = \\\\frac{4}{5}$ and $\\\\angle A < 90^\\\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\\\angle BAD = \\\\angle DAC$ and $\\\\angle BDC = 90^\\\\circ$. Suppose that $AD = 1$ and that $\\\\frac{BD}{CD} = \\\\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\\\frac{a\\\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.\\n\\nRemember to put your answer on its own line after \"Answer:\".',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the overall prompt (including problem and system prompt) in the OpenR1 datatset\n",
    "dataset[0][\"source_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7eb3aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In triangle $ABC$, $\\sin \\angle A = \\frac{4}{5}$ and $\\angle A < 90^\\circ$. Let $D$ be a point outside triangle $ABC$ such that $\\angle BAD = \\angle DAC$ and $\\angle BDC = 90^\\circ$. Suppose that $AD = 1$ and that $\\frac{BD}{CD} = \\frac{3}{2}$. If $AB + AC$ can be expressed in the form $\\frac{a\\sqrt{b}}{c}$ where $a, b, c$ are pairwise relatively prime integers, find $a + b + c$.\n"
     ]
    }
   ],
   "source": [
    "# the problem\n",
    "print(dataset[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9e3aa",
   "metadata": {},
   "source": [
    "Synthesis the dataset with customized system prompt and quetion(the name is prompt in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8179f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 283.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: {\n",
    "    \"prompt\": [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": x[\"prompt\"]}\n",
    "    ],\n",
    "    \"answer\": x['solution']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863143f",
   "metadata": {},
   "source": [
    "Extract the final answer from a structured text that contains both:\n",
    "- a reasoning section (e.g., <REASONING>...</REASONING>)\n",
    "- and a solution section (e.g., <SOLUTION>...</SOLUTION>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e493aa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'<end_working_out>.*?<SOLUTION>(.+?)</SOLUTION>[\\s]{0,}(?:<\\|endoftext\\|>)?[\\s]{0,}$',\n",
       "           re.MULTILINE|re.DOTALL|re.UNICODE)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Add optional EOS token matching\n",
    "solution_end_regex = r\"</SOLUTION>[\\s]{0,}\" + \\\n",
    "    \"(?:\" + re.escape(tokenizer.eos_token) + \")?\"\n",
    "\n",
    "match_format = re.compile(\n",
    "    rf\"{reasoning_end}.*?\"\\\n",
    "    rf\"{solution_start}(.+?){solution_end_regex}\"\\\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "match_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4dccdc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n2\\n']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case\n",
    "match_format.findall(\n",
    "    \"Let me think!<end_working_out>\"\\\n",
    "    f\"<SOLUTION>\\n2\\n</SOLUTION>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf13e9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['364']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_format.findall(\n",
    "    \"Let me think!<end_working_out>\"\\\n",
    "    f\"<SOLUTION>364</SOLUTION>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574cd87c",
   "metadata": {},
   "source": [
    "Create reward function to match the format \n",
    "- +3 points if the output matches the full format exactly\n",
    "- Partial reward if key format tags (<REASONING>, </REASONING>, etc.) are present (each adds +0.5).\n",
    "- Penalty (-1.0) if a required tag is missing or appears more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "add0b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_exactly(completions, **kwargs):\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Match if format is seen exactly!\n",
    "        if match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff0a0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_partially(completions, **kwargs):\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Count how many keywords are seen - we penalize if too many!\n",
    "        # If we see 1, then plus some points!\n",
    "\n",
    "        # No need to reward <start_working_out> since we always prepend it!\n",
    "        # score += 0.5 if response.count(reasoning_start) == 1 else -1.0\n",
    "        score += 0.5 if response.count(reasoning_end)   == 1 else -1.0\n",
    "        score += 0.5 if response.count(solution_start)  == 1 else -1.0\n",
    "        score += 0.5 if response.count(solution_end)    == 1 else -1.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb71197",
   "metadata": {},
   "source": [
    "Reward of penalize the generated content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "209a4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer(prompts, completions, answer, **kwargs):\n",
    "    question = prompts[0][-1]['content']\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        result.group(1)\n",
    "        if (result := match_format.search(r)) is not None else None for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(-2.0) # Note that it is append to scores not score, which means no answer=-2, then next run\n",
    "            continue\n",
    "        \n",
    "        # 5 points for correct answer\n",
    "        if guess  == true_answer:\n",
    "            score += 5.0\n",
    "\n",
    "        # Match if spaces are seen but less reward\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 3.5\n",
    "        \n",
    "        else:\n",
    "            # Reward the answer if it is close via ratios\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if ratio >= 0.9 and ratio <= 1.1:\n",
    "                    score += 2.0\n",
    "                elif ratio >= 0.8 and ratio <= 1.2:\n",
    "                    score += 1.5\n",
    "                else:\n",
    "                    score += -2.5\n",
    "            except:\n",
    "                score += -4.5\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b23b8",
   "metadata": {},
   "source": [
    "Remove commas such as 123,456 or extract the number in a sentence for example \"The solution is $20\" -> 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91b9885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.34']\n",
      "['123456']\n",
      "['-0.234']\n",
      "['17']\n"
     ]
    }
   ],
   "source": [
    "# Match numbers like 17, 123,456, 0.34, -0.234, 1,234,567.89\n",
    "match_numbers = re.compile(r\"-?(?:\\d{1,3}(?:,\\d{3})+|\\d+)(?:\\.\\d+)?\", re.MULTILINE | re.DOTALL)\n",
    "\n",
    "def find_numbers_clean(text):\n",
    "    \"\"\"Return numbers as strings with commas removed.\"\"\"\n",
    "    return [n.replace(\",\", \"\") for n in match_numbers.findall(text)]\n",
    "\n",
    "# If you'd like floats instead, use this:\n",
    "def find_numbers_float(text):\n",
    "    return [float(n.replace(\",\", \"\")) for n in match_numbers.findall(text)]\n",
    "\n",
    "# Tests\n",
    "print(find_numbers_clean(\"<SOLUTION>  0.34  </SOLUTION>\"))      # ['0.34']\n",
    "print(find_numbers_clean(\"<SOLUTION>  123,456  </SOLUTION>\"))   # ['123456']\n",
    "print(find_numbers_clean(\"<SOLUTION>  -0.234  </SOLUTION>\"))    # ['-0.234']\n",
    "print(find_numbers_clean(\"<SOLUTION> The solution is 17  </SOLUTION>\"))  # ['17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e37e9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "global PRINTED_TIMES\n",
    "PRINTED_TIMES = 0 # a counter that increments every time check_numbers is called.\n",
    "global PRINT_EVERY_STEPS\n",
    "PRINT_EVERY_STEPS = 5 # ets the frequency (here 5).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb501ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluate numeric answers extracted from model completions against ground truth.\n",
    "\n",
    "    Scoring (per item):\n",
    "      - 3.5  if the extracted numeric guess equals the true answer (after stripping & removing commas)\n",
    "      - -1.5 if a number was extracted but it does not equal the true answer\n",
    "      - -2.5 if no number could be extracted\n",
    "      - 0    if parsing fails unexpectedly\n",
    "\n",
    "    Args:\n",
    "        prompts:\n",
    "            A sequence of message lists. This function reads the question text from\n",
    "            `prompts[0][-1][\"content\"]`\n",
    "            Example shape: `[[{\"role\":\"user\",\"content\":\"...\"}], ...]`\n",
    "        completions:\n",
    "            A sequence of generation lists. Each item should be a list whose first element\n",
    "            has a `\"content\"` string, accessed as `completion[0][\"content\"]`.\n",
    "            Example shape: `[[{\"role\":\"assistant\",\"content\":\"...\"}], ...]`\n",
    "        answers:\n",
    "            Sequence of ground-truth answers (strings or numbers). Must align 1:1 with `completions`.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Scores aligned with `completions` / `answers`.\n",
    "\n",
    "    Notes:\n",
    "        - Compares numeric equality after normalizing commas in guesses.\n",
    "        - `answers` are cast to float via `float(str(answer).strip())`.\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1]['content']\n",
    "    responses = [completion[0][\"content\"] for completion in completions] # how to confirm it is right?\n",
    "\n",
    "\n",
    "    # apply reg.search to extract the answer, since the completion may contain other string.\n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_numbers.search(r)) is not None else None for r in responses\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    # Print only every few steps\n",
    "    global PRINTED_TIMES\n",
    "    global PRINT_EVERY_STEPS\n",
    "    if PRINTED_TIMES % PRINT_EVERY_STEPS == 0:\n",
    "        print(\n",
    "            '*'*20 + f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\"\n",
    "        )\n",
    "    PRINTED_TIMES += 1\n",
    "\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(-2.5)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            # Remove commas like in 123,456\n",
    "            guess       = float(guess.strip().replace(\",\", \"\"))\n",
    "            scores.append(3.5 if guess == true_answer else -1.5)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "31f327e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global PRINTED_TIMES\n",
    "PRINTED_TIMES = 0\n",
    "global PRINT_EVERY_STEPS\n",
    "PRINT_EVERY_STEPS = 5\n",
    "\n",
    "def check_numbers(prompts, completions, answer, **kwargs):\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_numbers.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    # Print only every few steps\n",
    "    global PRINTED_TIMES\n",
    "    global PRINT_EVERY_STEPS\n",
    "    if PRINTED_TIMES % PRINT_EVERY_STEPS == 0:\n",
    "        print(\n",
    "            '*'*20 + f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\"\n",
    "        )\n",
    "    PRINTED_TIMES += 1\n",
    "\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(-2.5)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            # Remove commas like in 123,456\n",
    "            guess       = float(guess.strip().replace(\",\", \"\"))\n",
    "            scores.append(3.5 if guess == true_answer else -1.5)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7652ab",
   "metadata": {},
   "source": [
    "Warlus operation explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d8470f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['42', '-3.14', None, '1']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regex to capture a number (with optional decimal part)\n",
    "match_numbers = re.compile(r\"(-?\\d+(?:\\.\\d+)?)\")\n",
    "\n",
    "responses = [\n",
    "    \"The answer is 42.\",\n",
    "    \"I think it's -3.14\",\n",
    "    \"No number here!\",\n",
    "    \"Maybe 1,234 is correct\"\n",
    "]\n",
    "extracted_responses = [\n",
    "    guess.group(1)\n",
    "    if (guess := match_numbers.search(r)) is not None else None\n",
    "    for r in responses\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Warlus operator (`:=`):\n",
    "does two things at once:\n",
    "1. Runs match_numbers.search(r)\n",
    "2. Saves the result into guess\n",
    "3. Returns the result so it can be used immediately in the expression\n",
    "\"\"\"\n",
    "\n",
    "print(extracted_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0156b378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 16]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 2, 3, 4]\n",
    "result = []\n",
    "for n in numbers:\n",
    "    x = n * n\n",
    "    if x > 5:\n",
    "        result.append(x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88d298d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 16]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 2, 3, 4]\n",
    "\n",
    "result = [x for n in numbers if (x := n*n) > 5]\n",
    "\n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ef53d",
   "metadata": {},
   "source": [
    "For stable traninig, we want to restrict the model_length\n",
    "1. remove the top 10% long prompts\n",
    "2. check the max model input length # it didn't involved in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "187340a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 135.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 181.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length =  127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 1000 (default)\n",
    "tokenized = dataset.map(\n",
    "    lambda x: {\"tokens\": tokenizer.apply_chat_template(x['prompt'], add_generation_prompt=True, tokenized=True)}, # add_generation_prompt = True for gettin the max possible length\n",
    "    batched= True\n",
    ")\n",
    "\n",
    "# calculate the length\n",
    "tokenized = tokenized.map(lambda x: {\"L\": len(x['tokens'])})\n",
    "\n",
    "maximum_length = int(np.quantile(tokenized['L'], 0.9))\n",
    "print(\"Max Length = \", maximum_length)\n",
    "\n",
    "# Filter only samples smaller than 90% max length\n",
    "dataset = dataset.select(np.where(np.array(tokenized[\"L\"]) <= maximum_length)[0])\n",
    "del tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1020be6",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "be7ae51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use GRPOTrainer in here, from-scratch implementation will be another folder\n",
    "\n",
    "max_prompt_length = maximum_length + 1 # + 1 just in case!\n",
    "max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "from vllm import SamplingParams\n",
    "vllm_sampling_params = SamplingParams(\n",
    "    min_p = 0.1,\n",
    "    top_p = 1.0,\n",
    "    top_k = -1,\n",
    "    seed = 3407,\n",
    "    stop = [tokenizer.eos_token],\n",
    "    include_stop_str_in_output = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52d383f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    vllm_sampling_params=vllm_sampling_params,\n",
    "    temperature=1.0,\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type='linear',\n",
    "    optim='adamw_8bit',\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1, # Increase to 4 for smoother training\n",
    "    num_generations=4,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_completion_length=max_completion_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 100,\n",
    "    save_steps = 100,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    "\n",
    "    # For optional training + evaluation\n",
    "    # fp16_full_eval = True,\n",
    "    # per_device_eval_batch_size = 4,\n",
    "    # eval_accumulation_steps = 1,\n",
    "    # eval_strategy = \"steps\",\n",
    "    # eval_steps = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3d675625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1 | Num Epochs = 100 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 16,515,072 of 4,038,983,168 (0.41% trained)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[123]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m trainer = GRPOTrainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     processing_class=tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# eval_dataset = new_dataset[\"test\"],\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/.venv/lib/python3.11/site-packages/transformers/trainer.py:2237\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2235\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2238\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/.venv/lib/python3.11/site-packages/accelerate/utils/memory.py:174\u001b[39m, in \u001b[36mfind_executable_batch_size.<locals>.decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo executable batch size found, reached zero.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:322\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:28\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/.venv/lib/python3.11/site-packages/trl/extras/profiling.py:98\u001b[39m, in \u001b[36mprofiling_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func.\u001b[34m__name__\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/GRPO/unsloth/unsloth_compiled_cache/UnslothGRPOTrainer.py:1613\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._prepare_inputs\u001b[39m\u001b[34m(self, generation_batch)\u001b[39m\n\u001b[32m   1610\u001b[39m generate_every = \u001b[38;5;28mself\u001b[39m.args.steps_per_generation * \u001b[38;5;28mself\u001b[39m.num_iterations\n\u001b[32m   1611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step % generate_every == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffered_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1612\u001b[39m     \u001b[38;5;66;03m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1613\u001b[39m     generation_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1614\u001b[39m     generation_batch = shuffle_tensor_dict(generation_batch)\n\u001b[32m   1615\u001b[39m     \u001b[38;5;28mself\u001b[39m._buffered_inputs = split_tensor_dict(generation_batch, \u001b[38;5;28mself\u001b[39m.args.steps_per_generation)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/GRPO/unsloth/unsloth_compiled_cache/UnslothGRPOTrainer.py:1880\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._generate_and_score_completions\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m   1875\u001b[39m     completions = completions_text\n\u001b[32m   1877\u001b[39m \u001b[38;5;66;03m# Calculate rewards for each reward function. rewards_per_func aggregates rewards across all processes. This is\u001b[39;00m\n\u001b[32m   1878\u001b[39m \u001b[38;5;66;03m# important because rewards will be normalized per group, and completions are distributed. We will later slice\u001b[39;00m\n\u001b[32m   1879\u001b[39m \u001b[38;5;66;03m# rewards_per_func to extract each process's subset.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m rewards_per_func = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_rewards\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_ids_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[38;5;66;03m# Apply weights to each reward function's output and sum\u001b[39;00m\n\u001b[32m   1883\u001b[39m rewards = (rewards_per_func * \u001b[38;5;28mself\u001b[39m.reward_weights.to(device).unsqueeze(\u001b[32m0\u001b[39m)).nansum(dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/.venv/lib/python3.11/site-packages/trl/extras/profiling.py:98\u001b[39m, in \u001b[36mprofiling_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func.\u001b[34m__name__\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLAlgoFromScratch/GRPO/unsloth/unsloth_compiled_cache/UnslothGRPOTrainer.py:1653\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._calculate_rewards\u001b[39m\u001b[34m(self, inputs, prompts, completions, completion_ids_list)\u001b[39m\n\u001b[32m   1651\u001b[39m         rewards_per_func[:, i] = reward_func(**reward_inputs).logits[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Shape (B*G,)\u001b[39;00m\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1653\u001b[39m     output_reward_func = \u001b[43mreward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletion_ids_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mreward_kwargs\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# Convert None values to NaN\u001b[39;00m\n\u001b[32m   1657\u001b[39m     output_reward_func = [reward \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch.nan \u001b[38;5;28;01mfor\u001b[39;00m reward \u001b[38;5;129;01min\u001b[39;00m output_reward_func]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mcheck_number\u001b[39m\u001b[34m(prompts, completions, answer, **kwargs)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_number\u001b[39m(prompts, completions, answer, **kwargs):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Evaluate numeric answers extracted from model completions against ground truth.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33;03m        - `answers` are cast to float via `float(str(answer).strip())`.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     question = \u001b[43mprompt\u001b[49m[\u001b[32m0\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     31\u001b[39m     responses = [completion[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m completion \u001b[38;5;129;01min\u001b[39;00m completions] \u001b[38;5;66;03m# how to confirm it is right?\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# apply reg.search to extract the answer, since the completion may contain other string.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs = [\n",
    "        match_format_exactly,\n",
    "        match_format_partially,\n",
    "        check_answer,\n",
    "        check_number\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    \n",
    "    # For optional training + evaluation\n",
    "    # train_dataset = new_dataset[\"train\"],\n",
    "    # eval_dataset = new_dataset[\"test\"],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset:\n",
    "    len_prompt = len(item['prompt'])\n",
    "    len_sol = len(item['solution'])\n",
    "\n",
    "    if len_prompt == 0:\n",
    "        print(0)\n",
    "\n",
    "    if len_sol == 0:\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b5808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0]['prompt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlalgofromscratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
