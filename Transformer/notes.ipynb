{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0366e+00, 1.0746e+00, 1.1140e+00, 1.1548e+00, 1.1971e+00,\n",
       "        1.2409e+00, 1.2864e+00, 1.3335e+00, 1.3824e+00, 1.4330e+00, 1.4855e+00,\n",
       "        1.5399e+00, 1.5963e+00, 1.6548e+00, 1.7154e+00, 1.7783e+00, 1.8434e+00,\n",
       "        1.9110e+00, 1.9810e+00, 2.0535e+00, 2.1288e+00, 2.2067e+00, 2.2876e+00,\n",
       "        2.3714e+00, 2.4582e+00, 2.5483e+00, 2.6416e+00, 2.7384e+00, 2.8387e+00,\n",
       "        2.9427e+00, 3.0505e+00, 3.1623e+00, 3.2781e+00, 3.3982e+00, 3.5227e+00,\n",
       "        3.6517e+00, 3.7855e+00, 3.9242e+00, 4.0679e+00, 4.2170e+00, 4.3714e+00,\n",
       "        4.5316e+00, 4.6976e+00, 4.8697e+00, 5.0481e+00, 5.2330e+00, 5.4247e+00,\n",
       "        5.6234e+00, 5.8294e+00, 6.0430e+00, 6.2643e+00, 6.4938e+00, 6.7317e+00,\n",
       "        6.9783e+00, 7.2339e+00, 7.4989e+00, 7.7737e+00, 8.0584e+00, 8.3536e+00,\n",
       "        8.6596e+00, 8.9769e+00, 9.3057e+00, 9.6466e+00, 1.0000e+01, 1.0366e+01,\n",
       "        1.0746e+01, 1.1140e+01, 1.1548e+01, 1.1971e+01, 1.2409e+01, 1.2864e+01,\n",
       "        1.3335e+01, 1.3824e+01, 1.4330e+01, 1.4855e+01, 1.5399e+01, 1.5963e+01,\n",
       "        1.6548e+01, 1.7154e+01, 1.7783e+01, 1.8434e+01, 1.9110e+01, 1.9810e+01,\n",
       "        2.0535e+01, 2.1288e+01, 2.2067e+01, 2.2876e+01, 2.3714e+01, 2.4582e+01,\n",
       "        2.5483e+01, 2.6416e+01, 2.7384e+01, 2.8387e+01, 2.9427e+01, 3.0505e+01,\n",
       "        3.1623e+01, 3.2781e+01, 3.3982e+01, 3.5227e+01, 3.6517e+01, 3.7855e+01,\n",
       "        3.9242e+01, 4.0679e+01, 4.2170e+01, 4.3714e+01, 4.5316e+01, 4.6976e+01,\n",
       "        4.8697e+01, 5.0481e+01, 5.2330e+01, 5.4247e+01, 5.6234e+01, 5.8294e+01,\n",
       "        6.0430e+01, 6.2643e+01, 6.4938e+01, 6.7317e+01, 6.9783e+01, 7.2339e+01,\n",
       "        7.4989e+01, 7.7737e+01, 8.0584e+01, 8.3536e+01, 8.6596e+01, 8.9769e+01,\n",
       "        9.3057e+01, 9.6466e+01, 1.0000e+02, 1.0366e+02, 1.0746e+02, 1.1140e+02,\n",
       "        1.1548e+02, 1.1971e+02, 1.2409e+02, 1.2864e+02, 1.3335e+02, 1.3824e+02,\n",
       "        1.4330e+02, 1.4855e+02, 1.5399e+02, 1.5963e+02, 1.6548e+02, 1.7154e+02,\n",
       "        1.7783e+02, 1.8434e+02, 1.9110e+02, 1.9810e+02, 2.0535e+02, 2.1288e+02,\n",
       "        2.2067e+02, 2.2876e+02, 2.3714e+02, 2.4582e+02, 2.5483e+02, 2.6416e+02,\n",
       "        2.7384e+02, 2.8387e+02, 2.9427e+02, 3.0505e+02, 3.1623e+02, 3.2781e+02,\n",
       "        3.3982e+02, 3.5227e+02, 3.6517e+02, 3.7855e+02, 3.9242e+02, 4.0679e+02,\n",
       "        4.2170e+02, 4.3714e+02, 4.5316e+02, 4.6976e+02, 4.8697e+02, 5.0481e+02,\n",
       "        5.2330e+02, 5.4247e+02, 5.6234e+02, 5.8294e+02, 6.0430e+02, 6.2643e+02,\n",
       "        6.4938e+02, 6.7317e+02, 6.9783e+02, 7.2339e+02, 7.4989e+02, 7.7737e+02,\n",
       "        8.0584e+02, 8.3536e+02, 8.6596e+02, 8.9769e+02, 9.3057e+02, 9.6466e+02,\n",
       "        1.0000e+03, 1.0366e+03, 1.0746e+03, 1.1140e+03, 1.1548e+03, 1.1971e+03,\n",
       "        1.2409e+03, 1.2864e+03, 1.3335e+03, 1.3824e+03, 1.4330e+03, 1.4855e+03,\n",
       "        1.5399e+03, 1.5963e+03, 1.6548e+03, 1.7154e+03, 1.7783e+03, 1.8434e+03,\n",
       "        1.9110e+03, 1.9810e+03, 2.0535e+03, 2.1288e+03, 2.2067e+03, 2.2876e+03,\n",
       "        2.3714e+03, 2.4582e+03, 2.5483e+03, 2.6416e+03, 2.7384e+03, 2.8387e+03,\n",
       "        2.9427e+03, 3.0505e+03, 3.1623e+03, 3.2781e+03, 3.3982e+03, 3.5227e+03,\n",
       "        3.6517e+03, 3.7855e+03, 3.9242e+03, 4.0679e+03, 4.2170e+03, 4.3714e+03,\n",
       "        4.5316e+03, 4.6976e+03, 4.8697e+03, 5.0481e+03, 5.2330e+03, 5.4247e+03,\n",
       "        5.6234e+03, 5.8294e+03, 6.0430e+03, 6.2643e+03, 6.4938e+03, 6.7317e+03,\n",
       "        6.9783e+03, 7.2339e+03, 7.4989e+03, 7.7737e+03, 8.0584e+03, 8.3536e+03,\n",
       "        8.6596e+03, 8.9769e+03, 9.3057e+03, 9.6466e+03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512\n",
    "torch.pow(torch.tensor(10000.0), torch.arange(0, d_model, 2).float() / d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
       "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
       "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
       "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
       "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
       "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
       "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
       "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
       "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
       "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
       "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
       "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
       "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
       "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
       "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
       "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
       "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
       "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
       "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
       "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
       "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
       "        504., 506., 508., 510.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,   3.,   5.,   7.,   9.,  11.,  13.,  15.,  17.,  19.,  21.,  23.,\n",
       "         25.,  27.,  29.,  31.,  33.,  35.,  37.,  39.,  41.,  43.,  45.,  47.,\n",
       "         49.,  51.,  53.,  55.,  57.,  59.,  61.,  63.,  65.,  67.,  69.,  71.,\n",
       "         73.,  75.,  77.,  79.,  81.,  83.,  85.,  87.,  89.,  91.,  93.,  95.,\n",
       "         97.,  99., 101., 103., 105., 107., 109., 111., 113., 115., 117., 119.,\n",
       "        121., 123., 125., 127., 129., 131., 133., 135., 137., 139., 141., 143.,\n",
       "        145., 147., 149., 151., 153., 155., 157., 159., 161., 163., 165., 167.,\n",
       "        169., 171., 173., 175., 177., 179., 181., 183., 185., 187., 189., 191.,\n",
       "        193., 195., 197., 199., 201., 203., 205., 207., 209., 211., 213., 215.,\n",
       "        217., 219., 221., 223., 225., 227., 229., 231., 233., 235., 237., 239.,\n",
       "        241., 243., 245., 247., 249., 251., 253., 255., 257., 259., 261., 263.,\n",
       "        265., 267., 269., 271., 273., 275., 277., 279., 281., 283., 285., 287.,\n",
       "        289., 291., 293., 295., 297., 299., 301., 303., 305., 307., 309., 311.,\n",
       "        313., 315., 317., 319., 321., 323., 325., 327., 329., 331., 333., 335.,\n",
       "        337., 339., 341., 343., 345., 347., 349., 351., 353., 355., 357., 359.,\n",
       "        361., 363., 365., 367., 369., 371., 373., 375., 377., 379., 381., 383.,\n",
       "        385., 387., 389., 391., 393., 395., 397., 399., 401., 403., 405., 407.,\n",
       "        409., 411., 413., 415., 417., 419., 421., 423., 425., 427., 429., 431.,\n",
       "        433., 435., 437., 439., 441., 443., 445., 447., 449., 451., 453., 455.,\n",
       "        457., 459., 461., 463., 465., 467., 469., 471., 473., 475., 477., 479.,\n",
       "        481., 483., 485., 487., 489., 491., 493., 495., 497., 499., 501., 503.,\n",
       "        505., 507., 509., 511.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "\n",
    "# Using torch.exp\n",
    "exp_values = torch.exp(torch.arange(0, d_model, 2).float() * (math.log(10000.0) / d_model))\n",
    "\n",
    "# Using torch.pow\n",
    "pow_values = torch.pow(torch.tensor(10000.0), torch.arange(0, d_model, 2).float() / d_model)\n",
    "\n",
    "# Check if both are the same\n",
    "print(torch.allclose(exp_values, pow_values))  # Should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 // 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask in Transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., -inf],\n",
       "        [5., 6., -inf, -inf]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_scores = torch.tensor([[1, 2, 3, 4],\n",
    "                            [5, 6, 7, 8]]).float()\n",
    "\n",
    "pad_mask = torch.tensor([[1, 1, 1, 0],\n",
    "                         [1, 1, 0, 0]])\n",
    "atten_scores.masked_fill(pad_mask == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the mask change the value in unwanted position to -inf, the value will become 0 after passing softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 5\n",
    "# diagonal = 0 : default\n",
    "# diagonal > 0 (up to length) : shift to upper\n",
    "# diagonal < 0 (up to length) : shift to lower\n",
    "# diagonal: the step toward up/down \n",
    "causal_mask = torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1) # torch.tril is lower triangular matrix\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False: allow attention\n",
    "# True: Masked(prevent future access)\n",
    "causal_mask.bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(causal_mask == 0).type(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $W_q \\times Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 8  # Model embedding size\n",
    "h = 2\n",
    "d_k = d_model // h\n",
    "q = torch.randn(batch_size, seq_len, d_model)\n",
    "k = torch.randn(batch_size, seq_len, d_model)\n",
    "v = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "w_q = nn.Linear(d_model, d_model)\n",
    "w_k = nn.Linear(d_model, d_model)\n",
    "w_v = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=8, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2956,  0.3017,  0.2095,  0.0102,  0.3108, -0.1231,  0.2842, -0.0630],\n",
       "        [-0.3499,  0.1831,  0.1254,  0.2108, -0.1379, -0.0171, -0.2342, -0.1333],\n",
       "        [-0.0991, -0.3430, -0.3122, -0.2325, -0.3493,  0.3280,  0.0291,  0.1152],\n",
       "        [-0.3421,  0.3067, -0.0454,  0.3392,  0.2325, -0.0272, -0.2155,  0.0931],\n",
       "        [ 0.1655, -0.2998, -0.0820,  0.1559,  0.0969, -0.2340,  0.3254,  0.2499],\n",
       "        [-0.0936, -0.2997, -0.2214,  0.2834,  0.0294,  0.1918,  0.0258,  0.2275],\n",
       "        [-0.3502,  0.0166, -0.2673,  0.1811, -0.2089, -0.1333, -0.2844,  0.2587],\n",
       "        [-0.1116,  0.2407,  0.0392,  0.2633,  0.3190, -0.0115,  0.0292,  0.2390]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2430,  0.1544, -0.3214, -0.0270, -0.2740, -0.2984,  0.0115, -0.0125],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2811,  2.7480, -0.7686,  0.5561,  0.4005, -0.2282,  1.3327,\n",
       "          -0.9030],\n",
       "         [-0.3814, -1.5869, -0.8211,  0.8302,  1.1556, -0.2978,  0.8301,\n",
       "          -1.0593],\n",
       "         [ 0.5936, -0.8763,  0.6146,  1.3449, -0.3268, -0.1439, -0.3934,\n",
       "           0.1920],\n",
       "         [-0.5722,  0.3083,  0.1601,  2.3065,  0.9289, -1.3594, -0.3375,\n",
       "           0.5340]],\n",
       "\n",
       "        [[ 1.0031, -0.4555, -1.0818, -1.1258, -0.2213,  0.5848,  0.3411,\n",
       "           1.5733],\n",
       "         [-0.3406,  1.5853, -0.3481, -0.7200,  0.6413,  1.0314, -0.0131,\n",
       "           1.4986],\n",
       "         [ 1.0077, -0.9961,  0.7193, -1.0495,  0.0678,  0.0714, -0.4262,\n",
       "          -1.1070],\n",
       "         [-0.2852, -0.2859, -0.1054,  0.0674, -0.4261,  1.0317, -0.5686,\n",
       "          -0.6572]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1264,  0.8836, -1.3063,  1.2058, -0.8600, -0.8772,  0.1460,\n",
       "           0.8616],\n",
       "         [ 0.1865, -0.1380, -0.2751, -0.0651,  0.5225,  0.3872, -0.2233,\n",
       "          -0.0223],\n",
       "         [ 0.0888,  0.2609, -0.5064, -0.0400,  0.1683,  0.1501,  0.1174,\n",
       "           0.0203],\n",
       "         [ 0.5505,  0.8204, -1.6753,  1.4138,  0.3170,  0.1604,  0.8132,\n",
       "           1.1689]],\n",
       "\n",
       "        [[ 0.0212, -0.9221,  0.7952, -0.8371,  0.2876,  0.1370,  0.0163,\n",
       "          -0.2642],\n",
       "         [ 0.5147,  0.0657, -0.2689,  0.6108, -0.6984, -0.3113,  0.2398,\n",
       "           0.7544],\n",
       "         [ 0.3411, -0.2746, -0.2003, -1.0633, -0.4565, -0.7979, -0.9291,\n",
       "          -0.8691],\n",
       "         [-0.3286,  0.4648,  0.2172, -0.0553, -0.8483, -0.1224,  0.0901,\n",
       "          -0.3574]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_q(q) equals to q * w_q.wieght + bias\n",
    "assert torch.allclose(w_q(q), torch.matmul(q, w_q.weight.T) + w_q.bias), \"w_q(q) doesn't equl to q*w_q^T + bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.allclose(w_q(q), q @ w_q.weight.T), 'they are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If w = nn.Linear(d_model, d_model, bias=False) then they will be the same\n",
    "w_test = nn.Linear(d_model, d_model, bias=False)\n",
    "assert torch.allclose(w_test(q), q @ w_test.weight.T), 'they are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = w_q(q)\n",
    "key = w_k(k)\n",
    "value = w_v(v)\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the batch size and seq_len, decompose the matrix into smaller matrix\n",
    "# so we can give each small matrix different head\n",
    "# later, we can perform independent attention calculations for each head\n",
    "query.view(query.shape[0], query.shape[1], h, d_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The reason for using (batch_size, h, seq_len, d_k) instead of (batch_size, seq_len, h, d_k) is that:\n",
    "\n",
    "The attention mechanism operates independently across heads.\n",
    "Each head will perform self-attention on its own set of d_k-dimensional vectors.\n",
    "The typical implementation of multi-head attention expects the shape (batch_size, h, seq_len, d_k).\n",
    "When performing matrix multiplications (like query @ key.T), we want to apply attention per head.\n",
    "This format is easier for batched computations in PyTorch and TensorFlow.\n",
    "\"\"\"\n",
    "\n",
    "query.view(query.shape[0], query.shape[1], h, d_k).transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.view(query.shape[0], query.shape[1], h, d_k).transpose(1, 2)\n",
    "key = key.view(key.shape[0], key.shape[1], h, d_k).transpose(1, 2)\n",
    "value = value.view(value.shape[0], value.shape[1], h, d_k).transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.1264,  0.1865,  0.0888,  0.5505],\n",
       "          [ 0.8836, -0.1380,  0.2609,  0.8204],\n",
       "          [-1.3063, -0.2751, -0.5064, -1.6753],\n",
       "          [ 1.2058, -0.0651, -0.0400,  1.4138]],\n",
       "\n",
       "         [[-0.8600,  0.5225,  0.1683,  0.3170],\n",
       "          [-0.8772,  0.3872,  0.1501,  0.1604],\n",
       "          [ 0.1460, -0.2233,  0.1174,  0.8132],\n",
       "          [ 0.8616, -0.0223,  0.0203,  1.1689]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0212,  0.5147,  0.3411, -0.3286],\n",
       "          [-0.9221,  0.0657, -0.2746,  0.4648],\n",
       "          [ 0.7952, -0.2689, -0.2003,  0.2172],\n",
       "          [-0.8371,  0.6108, -1.0633, -0.0553]],\n",
       "\n",
       "         [[ 0.2876, -0.6984, -0.4565, -0.8483],\n",
       "          [ 0.1370, -0.3113, -0.7979, -0.1224],\n",
       "          [ 0.0163,  0.2398, -0.9291,  0.0901],\n",
       "          [-0.2642,  0.7544, -0.8691, -0.3574]]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9157,  0.0513,  0.1330, -0.6412],\n",
       "          [-0.0147,  0.1114,  0.0712, -0.0262],\n",
       "          [-0.1894,  0.0404, -0.0327, -0.0787],\n",
       "          [-0.9802, -0.0308, -0.0956, -0.5266]],\n",
       "\n",
       "         [[ 0.3311,  0.1983,  0.4796, -0.2200],\n",
       "          [-0.1497, -0.0800, -0.1673,  0.0292],\n",
       "          [-0.0480,  0.0113, -0.0137,  0.0716],\n",
       "          [ 0.0246,  0.2638,  0.3976,  0.2193]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5027,  0.4139,  0.5343,  0.5886],\n",
       "          [-0.2383, -0.1402, -0.2087,  0.1509],\n",
       "          [ 0.5358,  0.4792,  0.1615,  0.2448],\n",
       "          [ 0.1215,  0.0500,  0.0221, -0.2017]],\n",
       "\n",
       "         [[ 0.0333, -0.1112, -0.0366, -0.0993],\n",
       "          [ 0.0420,  0.2686,  0.0544,  0.3847],\n",
       "          [-0.0233,  0.0463,  0.3182, -0.1123],\n",
       "          [ 0.1555,  0.2327, -0.1697,  0.0707]]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score = (query @ key.transpose(-2 ,-1)) / math.sqrt(d_k)\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Dropout Applied:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def numpy_dropout(x, p=0.5):\n",
    "    \"\"\"Applies dropout using NumPy with probability p\"\"\"\n",
    "    keep_prob = 1 - p\n",
    "    mask = np.random.binomial(n=1, p=keep_prob, size=x.shape)  # Create Bernoulli mask\n",
    "    return (x * mask) / keep_prob  # Scale to maintain expectation\n",
    "\n",
    "# Example input matrix\n",
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Apply dropout with probability p = 0.5\n",
    "dropout_output = numpy_dropout(x, p=0.5)\n",
    "\n",
    "print(\"Input Tensor:\\n\", x)\n",
    "print(\"Dropout Applied:\\n\", dropout_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide by 1-p for maintaining the expectation\n",
    "\n",
    "test this by multiple runs as follows, we can see the value is nearly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value of Input Tensor: 3.5\n",
      "Expected Value After Dropout (Averaged over 10000 runs): 3.5030\n"
     ]
    }
   ],
   "source": [
    "def numpy_dropout(x, p=0.5):\n",
    "    \"\"\"Applies dropout using NumPy with probability p\"\"\"\n",
    "    keep_prob = 1 - p\n",
    "    mask = np.random.binomial(n=1, p=keep_prob, size=x.shape)  # Create Bernoulli mask\n",
    "    return (x * mask) / keep_prob  # Scale to maintain expectation\n",
    "\n",
    "# Example input matrix\n",
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Compute expectation of the input\n",
    "expected_input = np.mean(x)\n",
    "\n",
    "# Run dropout multiple times and compute mean expectation\n",
    "num_trials = 10000\n",
    "expected_dropout_values = [np.mean(numpy_dropout(x, p=0.5)) for _ in range(num_trials)]\n",
    "\n",
    "# Compute the overall expectation across trials\n",
    "expected_dropout = np.mean(expected_dropout_values)\n",
    "\n",
    "print(\"Expected Value of Input Tensor:\", expected_input)\n",
    "print(\"Expected Value After Dropout (Averaged over {} runs): {:.4f}\".format(num_trials, expected_dropout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1 0.5 0.9]\n",
      "Bernoulli Samples: [0 3 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def numpy_bernoulli(probabilities):\n",
    "    \"\"\"Simulates torch.bernoulli using NumPy.\"\"\"\n",
    "    return np.random.binomial(n=3, p=probabilities)\n",
    "\n",
    "# Example probability tensor (same as in PyTorch example)\n",
    "probabilities = np.array([0.1, 0.5, 0.9])\n",
    "\n",
    "# Generate Bernoulli samples\n",
    "samples = numpy_bernoulli(probabilities)\n",
    "\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print(\"Bernoulli Samples:\", samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Token  ID\n",
      "0    [SOS]   2\n",
      "1        ,   4\n",
      "2        .   5\n",
      "3        !   9\n",
      "4    hello   7\n",
      "5     this  12\n",
      "6   banana   6\n",
      "7    [EOS]   3\n",
      "8    [PAD]   1\n",
      "9    [UNK]   0\n",
      "10    test   8\n",
      "11      is  11\n",
      "12       a  10\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from tokenizers.normalizers import Lowercase\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import pandas as pd\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"Hello world!\",\n",
    "    \"Hello ChatGPT!\",\n",
    "    \"This is a test sentence.\",\n",
    "    \"Hello, this is another test.\",\n",
    "    \"Test your tokenizer with a sample text.\",\n",
    "    \"Banana, banana, BANANA\"\n",
    "]\n",
    "\n",
    "# Initialize a WordLevel tokenizer\n",
    "tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\"))\n",
    "\n",
    "# Set normalization (lowercasing)\n",
    "tokenizer.normalizer = Lowercase()\n",
    "\n",
    "# Set pre-tokenizer (whitespace splitting)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Trainer with min_frequency=2\n",
    "trainer = trainers.WordLevelTrainer(\n",
    "    min_frequency=2,\n",
    "    special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"]\n",
    ")\n",
    "\n",
    "# Train tokenizer\n",
    "tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "vocab_df = pd.DataFrame(vocab.items(), columns=[\"Token\", \"ID\"])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(vocab_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', '[UNK]', '!'],\n",
       " ['hello', '[UNK]', '!'],\n",
       " ['this', 'is', 'a', 'test', '[UNK]', '.'],\n",
       " ['hello', ',', 'this', 'is', '[UNK]', 'test', '.'],\n",
       " ['test', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '.'],\n",
       " ['banana', ',', 'banana', ',', 'banana']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [tokenizer.encode(sentence).tokens for sentence in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " '[UNK]',\n",
       " '!',\n",
       " 'hello',\n",
       " '[UNK]',\n",
       " '!',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " '[UNK]',\n",
       " '.',\n",
       " 'hello',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " '[UNK]',\n",
       " 'test',\n",
       " '.',\n",
       " 'test',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'a',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '.',\n",
       " 'banana',\n",
       " ',',\n",
       " 'banana',\n",
       " ',',\n",
       " 'banana']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the list of tokenized words\n",
    "flat_tokenized_words = [word for sentence in tokenized_corpus for word in sentence]\n",
    "flat_tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Token",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "eb57b96b-c96c-42ad-87e8-6b8ea5ee2766",
       "rows": [
        [
         "0",
         "hello",
         "3"
        ],
        [
         "1",
         "[UNK]",
         "9"
        ],
        [
         "2",
         "!",
         "2"
        ],
        [
         "3",
         "this",
         "2"
        ],
        [
         "4",
         "is",
         "2"
        ],
        [
         "5",
         "a",
         "2"
        ],
        [
         "6",
         "test",
         "3"
        ],
        [
         "7",
         ".",
         "3"
        ],
        [
         "8",
         ",",
         "3"
        ],
        [
         "9",
         "banana",
         "3"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>banana</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token  Count\n",
       "0   hello      3\n",
       "1   [UNK]      9\n",
       "2       !      2\n",
       "3    this      2\n",
       "4      is      2\n",
       "5       a      2\n",
       "6    test      3\n",
       "7       .      3\n",
       "8       ,      3\n",
       "9  banana      3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each word in the vocabulary\n",
    "word_counts = Counter(flat_tokenized_words)\n",
    "word_count_df = pd.DataFrame(word_counts.items(), columns=[\"Token\", \"Count\"])\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  101, 2009, 2003, 1037, 2204, 2154,  102,    1,    2,    2,    2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tokens\n",
    "sos_token = torch.tensor([0])  # Start of Sequence <SOS>\n",
    "eos_token = torch.tensor([1])  # End of Sequence <EOS>\n",
    "pad_token = 2                  # Padding token\n",
    "\n",
    "# Example encoded tokens\n",
    "encoded_input_tokens = torch.tensor([101, 2009, 2003, 1037, 2204, 2154, 102])  # Main sequence\n",
    "encoded_num_padding_tokens = 3  # Number of padding tokens\n",
    "\n",
    "# Construct the encoded input using torch.cat()\n",
    "encoded_input = torch.cat([\n",
    "    sos_token,  \n",
    "    encoded_input_tokens,  \n",
    "    eos_token,  \n",
    "    torch.tensor([pad_token] * encoded_num_padding_tokens, dtype=torch.int64)\n",
    "])\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a is decoded_input, so there is no eos\n",
    "\"\"\"\n",
    "a = torch.tensor([0, 12, 13, 2 , 2]) # the real input is 2: 0 is SOS, 2 is pad\n",
    "b = 2\n",
    "(a != b).int() # False = 1: means the input rather thant pad token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build causal_mask with torch.ones\n",
    "causal_mask = torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1)\n",
    "\n",
    "# Use '&' to make the causal mask align with the length of the input sentence\n",
    "(a != b).int() & (causal_mask == 0).type(torch.int) # Convert the 1 to 0, 0 to 1: align with the (a != b).int(), 1 means the real input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
