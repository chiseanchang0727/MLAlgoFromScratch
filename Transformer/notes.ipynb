{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0366e+00, 1.0746e+00, 1.1140e+00, 1.1548e+00, 1.1971e+00,\n",
       "        1.2409e+00, 1.2864e+00, 1.3335e+00, 1.3824e+00, 1.4330e+00, 1.4855e+00,\n",
       "        1.5399e+00, 1.5963e+00, 1.6548e+00, 1.7154e+00, 1.7783e+00, 1.8434e+00,\n",
       "        1.9110e+00, 1.9810e+00, 2.0535e+00, 2.1288e+00, 2.2067e+00, 2.2876e+00,\n",
       "        2.3714e+00, 2.4582e+00, 2.5483e+00, 2.6416e+00, 2.7384e+00, 2.8387e+00,\n",
       "        2.9427e+00, 3.0505e+00, 3.1623e+00, 3.2781e+00, 3.3982e+00, 3.5227e+00,\n",
       "        3.6517e+00, 3.7855e+00, 3.9242e+00, 4.0679e+00, 4.2170e+00, 4.3714e+00,\n",
       "        4.5316e+00, 4.6976e+00, 4.8697e+00, 5.0481e+00, 5.2330e+00, 5.4247e+00,\n",
       "        5.6234e+00, 5.8294e+00, 6.0430e+00, 6.2643e+00, 6.4938e+00, 6.7317e+00,\n",
       "        6.9783e+00, 7.2339e+00, 7.4989e+00, 7.7737e+00, 8.0584e+00, 8.3536e+00,\n",
       "        8.6596e+00, 8.9769e+00, 9.3057e+00, 9.6466e+00, 1.0000e+01, 1.0366e+01,\n",
       "        1.0746e+01, 1.1140e+01, 1.1548e+01, 1.1971e+01, 1.2409e+01, 1.2864e+01,\n",
       "        1.3335e+01, 1.3824e+01, 1.4330e+01, 1.4855e+01, 1.5399e+01, 1.5963e+01,\n",
       "        1.6548e+01, 1.7154e+01, 1.7783e+01, 1.8434e+01, 1.9110e+01, 1.9810e+01,\n",
       "        2.0535e+01, 2.1288e+01, 2.2067e+01, 2.2876e+01, 2.3714e+01, 2.4582e+01,\n",
       "        2.5483e+01, 2.6416e+01, 2.7384e+01, 2.8387e+01, 2.9427e+01, 3.0505e+01,\n",
       "        3.1623e+01, 3.2781e+01, 3.3982e+01, 3.5227e+01, 3.6517e+01, 3.7855e+01,\n",
       "        3.9242e+01, 4.0679e+01, 4.2170e+01, 4.3714e+01, 4.5316e+01, 4.6976e+01,\n",
       "        4.8697e+01, 5.0481e+01, 5.2330e+01, 5.4247e+01, 5.6234e+01, 5.8294e+01,\n",
       "        6.0430e+01, 6.2643e+01, 6.4938e+01, 6.7317e+01, 6.9783e+01, 7.2339e+01,\n",
       "        7.4989e+01, 7.7737e+01, 8.0584e+01, 8.3536e+01, 8.6596e+01, 8.9769e+01,\n",
       "        9.3057e+01, 9.6466e+01, 1.0000e+02, 1.0366e+02, 1.0746e+02, 1.1140e+02,\n",
       "        1.1548e+02, 1.1971e+02, 1.2409e+02, 1.2864e+02, 1.3335e+02, 1.3824e+02,\n",
       "        1.4330e+02, 1.4855e+02, 1.5399e+02, 1.5963e+02, 1.6548e+02, 1.7154e+02,\n",
       "        1.7783e+02, 1.8434e+02, 1.9110e+02, 1.9810e+02, 2.0535e+02, 2.1288e+02,\n",
       "        2.2067e+02, 2.2876e+02, 2.3714e+02, 2.4582e+02, 2.5483e+02, 2.6416e+02,\n",
       "        2.7384e+02, 2.8387e+02, 2.9427e+02, 3.0505e+02, 3.1623e+02, 3.2781e+02,\n",
       "        3.3982e+02, 3.5227e+02, 3.6517e+02, 3.7855e+02, 3.9242e+02, 4.0679e+02,\n",
       "        4.2170e+02, 4.3714e+02, 4.5316e+02, 4.6976e+02, 4.8697e+02, 5.0481e+02,\n",
       "        5.2330e+02, 5.4247e+02, 5.6234e+02, 5.8294e+02, 6.0430e+02, 6.2643e+02,\n",
       "        6.4938e+02, 6.7317e+02, 6.9783e+02, 7.2339e+02, 7.4989e+02, 7.7737e+02,\n",
       "        8.0584e+02, 8.3536e+02, 8.6596e+02, 8.9769e+02, 9.3057e+02, 9.6466e+02,\n",
       "        1.0000e+03, 1.0366e+03, 1.0746e+03, 1.1140e+03, 1.1548e+03, 1.1971e+03,\n",
       "        1.2409e+03, 1.2864e+03, 1.3335e+03, 1.3824e+03, 1.4330e+03, 1.4855e+03,\n",
       "        1.5399e+03, 1.5963e+03, 1.6548e+03, 1.7154e+03, 1.7783e+03, 1.8434e+03,\n",
       "        1.9110e+03, 1.9810e+03, 2.0535e+03, 2.1288e+03, 2.2067e+03, 2.2876e+03,\n",
       "        2.3714e+03, 2.4582e+03, 2.5483e+03, 2.6416e+03, 2.7384e+03, 2.8387e+03,\n",
       "        2.9427e+03, 3.0505e+03, 3.1623e+03, 3.2781e+03, 3.3982e+03, 3.5227e+03,\n",
       "        3.6517e+03, 3.7855e+03, 3.9242e+03, 4.0679e+03, 4.2170e+03, 4.3714e+03,\n",
       "        4.5316e+03, 4.6976e+03, 4.8697e+03, 5.0481e+03, 5.2330e+03, 5.4247e+03,\n",
       "        5.6234e+03, 5.8294e+03, 6.0430e+03, 6.2643e+03, 6.4938e+03, 6.7317e+03,\n",
       "        6.9783e+03, 7.2339e+03, 7.4989e+03, 7.7737e+03, 8.0584e+03, 8.3536e+03,\n",
       "        8.6596e+03, 8.9769e+03, 9.3057e+03, 9.6466e+03])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512\n",
    "torch.pow(torch.tensor(10000.0), torch.arange(0, d_model, 2).float() / d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
       "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
       "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
       "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
       "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
       "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
       "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
       "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
       "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
       "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
       "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
       "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
       "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
       "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
       "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
       "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
       "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
       "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
       "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
       "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
       "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
       "        504., 506., 508., 510.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,   3.,   5.,   7.,   9.,  11.,  13.,  15.,  17.,  19.,  21.,  23.,\n",
       "         25.,  27.,  29.,  31.,  33.,  35.,  37.,  39.,  41.,  43.,  45.,  47.,\n",
       "         49.,  51.,  53.,  55.,  57.,  59.,  61.,  63.,  65.,  67.,  69.,  71.,\n",
       "         73.,  75.,  77.,  79.,  81.,  83.,  85.,  87.,  89.,  91.,  93.,  95.,\n",
       "         97.,  99., 101., 103., 105., 107., 109., 111., 113., 115., 117., 119.,\n",
       "        121., 123., 125., 127., 129., 131., 133., 135., 137., 139., 141., 143.,\n",
       "        145., 147., 149., 151., 153., 155., 157., 159., 161., 163., 165., 167.,\n",
       "        169., 171., 173., 175., 177., 179., 181., 183., 185., 187., 189., 191.,\n",
       "        193., 195., 197., 199., 201., 203., 205., 207., 209., 211., 213., 215.,\n",
       "        217., 219., 221., 223., 225., 227., 229., 231., 233., 235., 237., 239.,\n",
       "        241., 243., 245., 247., 249., 251., 253., 255., 257., 259., 261., 263.,\n",
       "        265., 267., 269., 271., 273., 275., 277., 279., 281., 283., 285., 287.,\n",
       "        289., 291., 293., 295., 297., 299., 301., 303., 305., 307., 309., 311.,\n",
       "        313., 315., 317., 319., 321., 323., 325., 327., 329., 331., 333., 335.,\n",
       "        337., 339., 341., 343., 345., 347., 349., 351., 353., 355., 357., 359.,\n",
       "        361., 363., 365., 367., 369., 371., 373., 375., 377., 379., 381., 383.,\n",
       "        385., 387., 389., 391., 393., 395., 397., 399., 401., 403., 405., 407.,\n",
       "        409., 411., 413., 415., 417., 419., 421., 423., 425., 427., 429., 431.,\n",
       "        433., 435., 437., 439., 441., 443., 445., 447., 449., 451., 453., 455.,\n",
       "        457., 459., 461., 463., 465., 467., 469., 471., 473., 475., 477., 479.,\n",
       "        481., 483., 485., 487., 489., 491., 493., 495., 497., 499., 501., 503.,\n",
       "        505., 507., 509., 511.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "\n",
    "# Using torch.exp\n",
    "exp_values = torch.exp(torch.arange(0, d_model, 2).float() * (math.log(10000.0) / d_model))\n",
    "\n",
    "# Using torch.pow\n",
    "pow_values = torch.pow(torch.tensor(10000.0), torch.arange(0, d_model, 2).float() / d_model)\n",
    "\n",
    "# Check if both are the same\n",
    "print(torch.allclose(exp_values, pow_values))  # Should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 // 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask in Transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., -inf],\n",
       "        [5., 6., -inf, -inf]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_scores = torch.tensor([[1, 2, 3, 4],\n",
    "                            [5, 6, 7, 8]]).float()\n",
    "\n",
    "pad_mask = torch.tensor([[1, 1, 1, 0],\n",
    "                         [1, 1, 0, 0]])\n",
    "atten_scores.masked_fill(pad_mask == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the mask change the value in unwanted position to -inf, the value will become 0 after passing softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 5\n",
    "# diagonal = 0 : default\n",
    "# diagonal > 0 (upper to length) : shift to upper\n",
    "# diagonal < 0 (upper to length) : shift to lower\n",
    "causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1) # torch.tril is lower triangular matrix\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False: allow attention\n",
    "# True: Masked(prevent future access)\n",
    "causal_mask.bool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $W_q \\times Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 8  # Model embedding size\n",
    "h = 2\n",
    "d_k = d_model // h\n",
    "q = torch.randn(batch_size, seq_len, d_model)\n",
    "k = torch.randn(batch_size, seq_len, d_model)\n",
    "v = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "w_q = nn.Linear(d_model, d_model)\n",
    "w_k = nn.Linear(d_model, d_model)\n",
    "w_v = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=8, bias=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2111, -0.1161,  0.1885, -0.0730,  0.2030, -0.3014,  0.0864,  0.0759],\n",
       "        [ 0.1219, -0.1910,  0.1038,  0.0461,  0.3176,  0.0714, -0.2393,  0.0059],\n",
       "        [-0.0884,  0.2548,  0.0199, -0.2067,  0.1611,  0.2984,  0.1323,  0.2228],\n",
       "        [-0.3201,  0.0113, -0.0106, -0.1457, -0.2766, -0.1569, -0.3010,  0.0380],\n",
       "        [ 0.1460, -0.2015, -0.0079,  0.0074,  0.2680,  0.3047,  0.2166,  0.1411],\n",
       "        [-0.2245,  0.2185,  0.2517,  0.1320,  0.2007,  0.2198,  0.0316, -0.1587],\n",
       "        [ 0.2890, -0.2662, -0.1288, -0.1369, -0.2060,  0.3290, -0.2989,  0.0451],\n",
       "        [-0.2206,  0.2229,  0.2288,  0.2423, -0.2317,  0.1357, -0.0972,  0.2270]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0154, -0.3341,  0.2655,  0.2718,  0.2809, -0.3188, -0.0718, -0.2876],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7132, -0.2739, -0.4353, -1.6998, -0.0278, -1.7315, -0.0546,\n",
       "          -1.1710],\n",
       "         [ 1.5169, -0.9338, -0.2130, -0.0695,  0.2930,  0.2094,  0.9007,\n",
       "          -0.6683],\n",
       "         [-0.2447,  0.2697,  0.7474,  0.6196, -0.4493,  0.6622, -0.4022,\n",
       "          -0.7072],\n",
       "         [ 0.1573, -0.6627, -2.5437, -0.2119,  1.9522,  0.7903, -0.0467,\n",
       "           0.0662]],\n",
       "\n",
       "        [[ 0.7824, -0.2996,  0.8681,  0.1862,  0.2521, -0.7392,  0.7083,\n",
       "          -0.1551],\n",
       "         [ 1.0007,  0.7010,  1.1217,  1.3078,  0.3737, -0.0953,  0.0075,\n",
       "          -0.3924],\n",
       "         [ 0.6895, -1.0957, -0.9057, -0.2559, -0.9743,  0.2925, -1.4120,\n",
       "          -0.0476],\n",
       "         [-1.5162,  0.6263,  0.9453,  0.1660,  1.5419, -2.1466, -0.0731,\n",
       "          -3.0045]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4601, -0.2618,  0.2760, -0.0117,  0.1811,  0.7136, -0.6927,\n",
       "           0.5770],\n",
       "         [ 0.4142,  1.0766, -1.0255,  0.2859,  0.1066,  0.4603,  0.7750,\n",
       "          -0.8607],\n",
       "         [ 0.4098,  0.5577,  0.1919, -0.0599,  0.5664,  0.7690, -0.1441,\n",
       "          -0.3678],\n",
       "         [ 0.4016, -0.2982,  0.2070,  0.1092, -0.5403,  1.0988, -0.0518,\n",
       "          -0.4172]],\n",
       "\n",
       "        [[ 0.1227, -0.8128,  0.0164,  0.5537, -0.7277,  0.7686,  0.0435,\n",
       "           0.2968],\n",
       "         [ 0.9401,  0.0824,  0.0732,  0.3911,  0.8812, -0.0277,  0.2050,\n",
       "           0.1086],\n",
       "         [ 1.5102,  0.2171, -0.3944,  0.9532, -0.2193,  0.5461,  1.1265,\n",
       "           0.7569],\n",
       "         [ 0.5780,  0.2778, -0.2590, -0.0228, -0.1115,  0.3983,  0.7533,\n",
       "           0.2462]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_q(q) equals to q * w_q.wieght + bias\n",
    "assert torch.allclose(w_q(q), torch.matmul(q, w_q.weight.T) + w_q.bias), \"w_q(q) doesn't equl to q*w_q^T + bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "they are different",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(w_q(q), q \u001b[38;5;241m@\u001b[39m w_q\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mT), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthey are different\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: they are different"
     ]
    }
   ],
   "source": [
    "assert torch.allclose(w_q(q), q @ w_q.weight.T), 'they are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If w = nn.Linear(d_model, d_model, bias=False) then they will be the same\n",
    "w_test = nn.Linear(d_model, d_model, bias=False)\n",
    "assert torch.allclose(w_test(q), q @ w_test.weight.T), 'they are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = w_q(q)\n",
    "key = w_k(k)\n",
    "value = w_v(v)\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2, 4])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the batch size and seq_len, decompose the matrix into smaller matrix\n",
    "# so we can give each small matrix different head\n",
    "# later, we can perform independent attention calculations for each head\n",
    "query.view(query.shape[0], query.shape[1], h, d_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4, 4])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The reason for using (batch_size, h, seq_len, d_k) instead of (batch_size, seq_len, h, d_k) is that:\n",
    "\n",
    "The attention mechanism operates independently across heads.\n",
    "Each head will perform self-attention on its own set of d_k-dimensional vectors.\n",
    "The typical implementation of multi-head attention expects the shape (batch_size, h, seq_len, d_k).\n",
    "When performing matrix multiplications (like query @ key.T), we want to apply attention per head.\n",
    "This format is easier for batched computations in PyTorch and TensorFlow.\n",
    "\"\"\"\n",
    "\n",
    "query.view(query.shape[0], query.shape[1], h, d_k).transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.view(query.shape[0], query.shape[1], h, d_k).transpose(1, 2)\n",
    "key = key.view(key.shape[0], key.shape[1], h, d_k).transpose(1, 2)\n",
    "value = value.view(value.shape[0], value.shape[1], h, d_k).transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4601,  0.4142,  0.4098,  0.4016],\n",
       "          [-0.2618,  1.0766,  0.5577, -0.2982],\n",
       "          [ 0.2760, -1.0255,  0.1919,  0.2070],\n",
       "          [-0.0117,  0.2859, -0.0599,  0.1092]],\n",
       "\n",
       "         [[ 0.1811,  0.1066,  0.5664, -0.5403],\n",
       "          [ 0.7136,  0.4603,  0.7690,  1.0988],\n",
       "          [-0.6927,  0.7750, -0.1441, -0.0518],\n",
       "          [ 0.5770, -0.8607, -0.3678, -0.4172]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1227,  0.9401,  1.5102,  0.5780],\n",
       "          [-0.8128,  0.0824,  0.2171,  0.2778],\n",
       "          [ 0.0164,  0.0732, -0.3944, -0.2590],\n",
       "          [ 0.5537,  0.3911,  0.9532, -0.0228]],\n",
       "\n",
       "         [[-0.7277,  0.8812, -0.2193, -0.1115],\n",
       "          [ 0.7686, -0.0277,  0.5461,  0.3983],\n",
       "          [ 0.0435,  0.2050,  1.1265,  0.7533],\n",
       "          [ 0.2968,  0.1086,  0.7569,  0.2462]]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0890,  0.0380,  0.1451,  0.0384],\n",
       "          [-0.2554, -0.2696, -0.3594, -0.3541],\n",
       "          [ 0.0490,  0.1333, -0.0733, -0.1779],\n",
       "          [ 0.0635,  0.1299, -0.0178,  0.3031]],\n",
       "\n",
       "         [[ 0.0316, -0.3110,  0.0640,  0.2993],\n",
       "          [ 0.3691,  0.3426, -0.1249,  0.1919],\n",
       "          [ 0.4070,  0.1153,  0.1259,  0.2641],\n",
       "          [-0.0034, -0.1989, -0.5468,  0.4380]]],\n",
       "\n",
       "\n",
       "        [[[-0.0040,  0.2876,  0.2494,  0.2321],\n",
       "          [-0.1905, -0.3061,  0.0460,  0.0161],\n",
       "          [-0.3534, -0.5675, -0.0960,  0.0213],\n",
       "          [-0.2530, -0.3804, -0.1190, -0.1752]],\n",
       "\n",
       "         [[-0.3690, -0.5342, -0.0820, -0.2274],\n",
       "          [ 0.4662,  0.2550,  0.1954,  0.3145],\n",
       "          [-0.0350, -0.7330,  0.2087, -0.0320],\n",
       "          [ 0.1691, -0.3480,  0.1701,  0.0909]]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score = (query @ key.transpose(-2 ,-1)) / math.sqrt(d_k)\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Dropout Applied:\n",
      " [[2. 0. 6.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def numpy_dropout(x, p=0.5):\n",
    "    \"\"\"Applies dropout using NumPy with probability p\"\"\"\n",
    "    keep_prob = 1 - p\n",
    "    mask = np.random.binomial(n=1, p=keep_prob, size=x.shape)  # Create Bernoulli mask\n",
    "    return (x * mask) / keep_prob  # Scale to maintain expectation\n",
    "\n",
    "# Example input matrix\n",
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Apply dropout with probability p = 0.5\n",
    "dropout_output = numpy_dropout(x, p=0.5)\n",
    "\n",
    "print(\"Input Tensor:\\n\", x)\n",
    "print(\"Dropout Applied:\\n\", dropout_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide by 1-p for maintaining the expectation\n",
    "\n",
    "test this by multiple runs as follows, we can see the value is nearly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value of Input Tensor: 3.5\n",
      "Expected Value After Dropout (Averaged over 10000 runs): 3.4921\n"
     ]
    }
   ],
   "source": [
    "def numpy_dropout(x, p=0.5):\n",
    "    \"\"\"Applies dropout using NumPy with probability p\"\"\"\n",
    "    keep_prob = 1 - p\n",
    "    mask = np.random.binomial(n=1, p=keep_prob, size=x.shape)  # Create Bernoulli mask\n",
    "    return (x * mask) / keep_prob  # Scale to maintain expectation\n",
    "\n",
    "# Example input matrix\n",
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Compute expectation of the input\n",
    "expected_input = np.mean(x)\n",
    "\n",
    "# Run dropout multiple times and compute mean expectation\n",
    "num_trials = 10000\n",
    "expected_dropout_values = [np.mean(numpy_dropout(x, p=0.5)) for _ in range(num_trials)]\n",
    "\n",
    "# Compute the overall expectation across trials\n",
    "expected_dropout = np.mean(expected_dropout_values)\n",
    "\n",
    "print(\"Expected Value of Input Tensor:\", expected_input)\n",
    "print(\"Expected Value After Dropout (Averaged over {} runs): {:.4f}\".format(num_trials, expected_dropout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1 0.5 0.9]\n",
      "Bernoulli Samples: [0 2 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def numpy_bernoulli(probabilities):\n",
    "    \"\"\"Simulates torch.bernoulli using NumPy.\"\"\"\n",
    "    return np.random.binomial(n=3, p=probabilities)\n",
    "\n",
    "# Example probability tensor (same as in PyTorch example)\n",
    "probabilities = np.array([0.1, 0.5, 0.9])\n",
    "\n",
    "# Generate Bernoulli samples\n",
    "samples = numpy_bernoulli(probabilities)\n",
    "\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print(\"Bernoulli Samples:\", samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
