{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0366e+00, 1.0746e+00, 1.1140e+00, 1.1548e+00, 1.1971e+00,\n",
       "        1.2409e+00, 1.2864e+00, 1.3335e+00, 1.3824e+00, 1.4330e+00, 1.4855e+00,\n",
       "        1.5399e+00, 1.5963e+00, 1.6548e+00, 1.7154e+00, 1.7783e+00, 1.8434e+00,\n",
       "        1.9110e+00, 1.9810e+00, 2.0535e+00, 2.1288e+00, 2.2067e+00, 2.2876e+00,\n",
       "        2.3714e+00, 2.4582e+00, 2.5483e+00, 2.6416e+00, 2.7384e+00, 2.8387e+00,\n",
       "        2.9427e+00, 3.0505e+00, 3.1623e+00, 3.2781e+00, 3.3982e+00, 3.5227e+00,\n",
       "        3.6517e+00, 3.7855e+00, 3.9242e+00, 4.0679e+00, 4.2170e+00, 4.3714e+00,\n",
       "        4.5316e+00, 4.6976e+00, 4.8697e+00, 5.0481e+00, 5.2330e+00, 5.4247e+00,\n",
       "        5.6234e+00, 5.8294e+00, 6.0430e+00, 6.2643e+00, 6.4938e+00, 6.7317e+00,\n",
       "        6.9783e+00, 7.2339e+00, 7.4989e+00, 7.7737e+00, 8.0584e+00, 8.3536e+00,\n",
       "        8.6596e+00, 8.9769e+00, 9.3057e+00, 9.6466e+00, 1.0000e+01, 1.0366e+01,\n",
       "        1.0746e+01, 1.1140e+01, 1.1548e+01, 1.1971e+01, 1.2409e+01, 1.2864e+01,\n",
       "        1.3335e+01, 1.3824e+01, 1.4330e+01, 1.4855e+01, 1.5399e+01, 1.5963e+01,\n",
       "        1.6548e+01, 1.7154e+01, 1.7783e+01, 1.8434e+01, 1.9110e+01, 1.9810e+01,\n",
       "        2.0535e+01, 2.1288e+01, 2.2067e+01, 2.2876e+01, 2.3714e+01, 2.4582e+01,\n",
       "        2.5483e+01, 2.6416e+01, 2.7384e+01, 2.8387e+01, 2.9427e+01, 3.0505e+01,\n",
       "        3.1623e+01, 3.2781e+01, 3.3982e+01, 3.5227e+01, 3.6517e+01, 3.7855e+01,\n",
       "        3.9242e+01, 4.0679e+01, 4.2170e+01, 4.3714e+01, 4.5316e+01, 4.6976e+01,\n",
       "        4.8697e+01, 5.0481e+01, 5.2330e+01, 5.4247e+01, 5.6234e+01, 5.8294e+01,\n",
       "        6.0430e+01, 6.2643e+01, 6.4938e+01, 6.7317e+01, 6.9783e+01, 7.2339e+01,\n",
       "        7.4989e+01, 7.7737e+01, 8.0584e+01, 8.3536e+01, 8.6596e+01, 8.9769e+01,\n",
       "        9.3057e+01, 9.6466e+01, 1.0000e+02, 1.0366e+02, 1.0746e+02, 1.1140e+02,\n",
       "        1.1548e+02, 1.1971e+02, 1.2409e+02, 1.2864e+02, 1.3335e+02, 1.3824e+02,\n",
       "        1.4330e+02, 1.4855e+02, 1.5399e+02, 1.5963e+02, 1.6548e+02, 1.7154e+02,\n",
       "        1.7783e+02, 1.8434e+02, 1.9110e+02, 1.9810e+02, 2.0535e+02, 2.1288e+02,\n",
       "        2.2067e+02, 2.2876e+02, 2.3714e+02, 2.4582e+02, 2.5483e+02, 2.6416e+02,\n",
       "        2.7384e+02, 2.8387e+02, 2.9427e+02, 3.0505e+02, 3.1623e+02, 3.2781e+02,\n",
       "        3.3982e+02, 3.5227e+02, 3.6517e+02, 3.7855e+02, 3.9242e+02, 4.0679e+02,\n",
       "        4.2170e+02, 4.3714e+02, 4.5316e+02, 4.6976e+02, 4.8697e+02, 5.0481e+02,\n",
       "        5.2330e+02, 5.4247e+02, 5.6234e+02, 5.8294e+02, 6.0430e+02, 6.2643e+02,\n",
       "        6.4938e+02, 6.7317e+02, 6.9783e+02, 7.2339e+02, 7.4989e+02, 7.7737e+02,\n",
       "        8.0584e+02, 8.3536e+02, 8.6596e+02, 8.9769e+02, 9.3057e+02, 9.6466e+02,\n",
       "        1.0000e+03, 1.0366e+03, 1.0746e+03, 1.1140e+03, 1.1548e+03, 1.1971e+03,\n",
       "        1.2409e+03, 1.2864e+03, 1.3335e+03, 1.3824e+03, 1.4330e+03, 1.4855e+03,\n",
       "        1.5399e+03, 1.5963e+03, 1.6548e+03, 1.7154e+03, 1.7783e+03, 1.8434e+03,\n",
       "        1.9110e+03, 1.9810e+03, 2.0535e+03, 2.1288e+03, 2.2067e+03, 2.2876e+03,\n",
       "        2.3714e+03, 2.4582e+03, 2.5483e+03, 2.6416e+03, 2.7384e+03, 2.8387e+03,\n",
       "        2.9427e+03, 3.0505e+03, 3.1623e+03, 3.2781e+03, 3.3982e+03, 3.5227e+03,\n",
       "        3.6517e+03, 3.7855e+03, 3.9242e+03, 4.0679e+03, 4.2170e+03, 4.3714e+03,\n",
       "        4.5316e+03, 4.6976e+03, 4.8697e+03, 5.0481e+03, 5.2330e+03, 5.4247e+03,\n",
       "        5.6234e+03, 5.8294e+03, 6.0430e+03, 6.2643e+03, 6.4938e+03, 6.7317e+03,\n",
       "        6.9783e+03, 7.2339e+03, 7.4989e+03, 7.7737e+03, 8.0584e+03, 8.3536e+03,\n",
       "        8.6596e+03, 8.9769e+03, 9.3057e+03, 9.6466e+03])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512\n",
    "torch.pow(torch.tensor(10000.0), torch.arange(0, d_model, 2).float() / d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
       "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
       "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
       "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
       "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
       "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
       "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
       "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
       "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
       "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
       "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
       "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
       "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
       "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
       "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
       "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
       "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
       "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
       "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
       "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
       "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
       "        504., 506., 508., 510.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.,   3.,   5.,   7.,   9.,  11.,  13.,  15.,  17.,  19.,  21.,  23.,\n",
       "         25.,  27.,  29.,  31.,  33.,  35.,  37.,  39.,  41.,  43.,  45.,  47.,\n",
       "         49.,  51.,  53.,  55.,  57.,  59.,  61.,  63.,  65.,  67.,  69.,  71.,\n",
       "         73.,  75.,  77.,  79.,  81.,  83.,  85.,  87.,  89.,  91.,  93.,  95.,\n",
       "         97.,  99., 101., 103., 105., 107., 109., 111., 113., 115., 117., 119.,\n",
       "        121., 123., 125., 127., 129., 131., 133., 135., 137., 139., 141., 143.,\n",
       "        145., 147., 149., 151., 153., 155., 157., 159., 161., 163., 165., 167.,\n",
       "        169., 171., 173., 175., 177., 179., 181., 183., 185., 187., 189., 191.,\n",
       "        193., 195., 197., 199., 201., 203., 205., 207., 209., 211., 213., 215.,\n",
       "        217., 219., 221., 223., 225., 227., 229., 231., 233., 235., 237., 239.,\n",
       "        241., 243., 245., 247., 249., 251., 253., 255., 257., 259., 261., 263.,\n",
       "        265., 267., 269., 271., 273., 275., 277., 279., 281., 283., 285., 287.,\n",
       "        289., 291., 293., 295., 297., 299., 301., 303., 305., 307., 309., 311.,\n",
       "        313., 315., 317., 319., 321., 323., 325., 327., 329., 331., 333., 335.,\n",
       "        337., 339., 341., 343., 345., 347., 349., 351., 353., 355., 357., 359.,\n",
       "        361., 363., 365., 367., 369., 371., 373., 375., 377., 379., 381., 383.,\n",
       "        385., 387., 389., 391., 393., 395., 397., 399., 401., 403., 405., 407.,\n",
       "        409., 411., 413., 415., 417., 419., 421., 423., 425., 427., 429., 431.,\n",
       "        433., 435., 437., 439., 441., 443., 445., 447., 449., 451., 453., 455.,\n",
       "        457., 459., 461., 463., 465., 467., 469., 471., 473., 475., 477., 479.,\n",
       "        481., 483., 485., 487., 489., 491., 493., 495., 497., 499., 501., 503.,\n",
       "        505., 507., 509., 511.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, d_model, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "\n",
    "# Using torch.exp\n",
    "exp_values = torch.exp(torch.arange(0, d_model, 2).float() * (math.log(10000.0) / d_model))\n",
    "\n",
    "# Using torch.pow\n",
    "pow_values = torch.pow(torch.tensor(10000.0), torch.arange(0, d_model, 2).float() / d_model)\n",
    "\n",
    "# Check if both are the same\n",
    "print(torch.allclose(exp_values, pow_values))  # Should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 // 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask in Transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., -inf],\n",
       "        [5., 6., -inf, -inf]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_scores = torch.tensor([[1, 2, 3, 4],\n",
    "                            [5, 6, 7, 8]]).float()\n",
    "\n",
    "pad_mask = torch.tensor([[1, 1, 1, 0],\n",
    "                         [1, 1, 0, 0]])\n",
    "atten_scores.masked_fill(pad_mask == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the mask change the value in unwanted position to -inf, the value will become 0 after passing softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 5\n",
    "# diagonal = 0 : default\n",
    "# diagonal > 0 (up to length) : shift to upper\n",
    "# diagonal < 0 (up to length) : shift to lower\n",
    "# diagonal: the step toward up/down \n",
    "causal_mask = torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1) # torch.tril is lower triangular matrix\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False, False]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False: allow attention\n",
    "# True: Masked(prevent future access)\n",
    "causal_mask.bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(causal_mask == 0).type(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $W_q \\times Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 5\n",
    "d_model = 8  # Model embedding size\n",
    "h = 2\n",
    "d_k = d_model // h\n",
    "q = torch.randn(batch_size, seq_len, d_model)\n",
    "k = torch.randn(batch_size, seq_len, d_model)\n",
    "v = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "w_q = nn.Linear(d_model, d_model)\n",
    "w_k = nn.Linear(d_model, d_model)\n",
    "w_v = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=8, bias=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1428,  0.3431,  0.2994, -0.2965, -0.3392, -0.1656, -0.0291,  0.3435],\n",
       "        [-0.0415,  0.2341,  0.1061, -0.3383, -0.3043, -0.2228, -0.2744, -0.1954],\n",
       "        [-0.0100, -0.3456,  0.2087,  0.0631, -0.0827, -0.0090,  0.1976, -0.2517],\n",
       "        [ 0.2419,  0.0615, -0.3207, -0.0789,  0.3107, -0.1104, -0.1111,  0.0375],\n",
       "        [ 0.1974, -0.2735, -0.1036, -0.1101, -0.1175,  0.3353, -0.0677,  0.0912],\n",
       "        [ 0.0311,  0.0332, -0.2990, -0.1517,  0.0467,  0.3297,  0.1928, -0.2025],\n",
       "        [ 0.1485,  0.3028, -0.3213,  0.3197,  0.0089, -0.1715, -0.0711, -0.2443],\n",
       "        [-0.0366,  0.1962, -0.1337,  0.0010, -0.0388, -0.1590, -0.0984, -0.0795]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3143, -0.2821,  0.2414,  0.3498, -0.2771,  0.3446, -0.3180,  0.3464],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0353, -0.7473,  0.5334, -1.1285, -0.1148,  0.5366, -1.0217,\n",
       "           0.3782],\n",
       "         [ 0.3393,  0.2364,  0.5980, -0.0357,  1.4332, -0.6502,  1.2400,\n",
       "          -0.3136],\n",
       "         [ 0.5190, -0.4202,  1.8979, -0.1536,  0.8054, -0.5070,  0.2912,\n",
       "          -0.6475],\n",
       "         [ 2.0307, -0.6709, -1.5005,  0.4828,  0.6329,  0.5436,  0.8358,\n",
       "          -0.6920],\n",
       "         [-1.1621,  2.2484,  1.8086, -0.4363, -0.2893,  1.6981, -0.1453,\n",
       "          -0.8524]],\n",
       "\n",
       "        [[ 0.0945,  1.1840, -1.0047, -0.0799,  0.2158, -2.0745, -0.4414,\n",
       "          -0.2626],\n",
       "         [-0.3234,  0.2133, -0.4673, -0.9813, -0.4884, -1.5280, -0.3162,\n",
       "          -1.3755],\n",
       "         [-0.1343, -1.5692,  0.5080,  0.6149, -1.0885, -0.8093, -0.5187,\n",
       "          -1.1083],\n",
       "         [ 0.1174, -0.3709,  0.6636,  0.3416,  1.1465, -1.8643, -0.0097,\n",
       "           0.8427],\n",
       "         [ 0.8460, -1.8956,  1.5724, -0.7767,  0.6167,  0.0636, -1.0848,\n",
       "          -1.5269]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0384,  0.1017,  0.2470,  0.2632,  0.3002,  0.2306, -1.1840,\n",
       "           0.1156],\n",
       "         [-0.5174, -0.7355,  0.4901,  0.6250, -0.8318,  0.3447, -0.2869,\n",
       "           0.2512],\n",
       "         [-0.1906, -0.2343,  0.9263,  0.1026, -0.5829, -0.1397, -0.7956,\n",
       "           0.0633],\n",
       "         [-1.4137, -1.2537,  0.4525,  1.2607,  0.3977,  1.2709,  0.4389,\n",
       "           0.2033],\n",
       "         [ 0.4905,  0.5481,  0.0202, -0.6318, -0.7254,  0.5996, -0.6056,\n",
       "           0.4111]],\n",
       "\n",
       "        [[ 0.0212,  0.4806, -0.4036,  1.1092, -1.1845, -0.0064,  0.8050,\n",
       "           1.0954],\n",
       "         [-0.1808,  0.9083,  0.3494,  0.5124, -0.8019,  0.3211,  0.1512,\n",
       "           0.8639],\n",
       "         [-0.7642,  0.0723,  1.2037, -0.2235, -0.2041, -0.1502, -0.3431,\n",
       "           0.2860],\n",
       "         [-0.1178, -0.5145,  0.2365,  0.7103, -0.9412, -0.6479, -0.3922,\n",
       "           0.3669],\n",
       "         [-0.8553,  0.0628,  1.2856,  0.2428,  0.2140,  0.1054, -1.0753,\n",
       "          -0.0735]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_q(q) equals to q * w_q.wieght + bias\n",
    "assert torch.allclose(w_q(q), torch.matmul(q, w_q.weight.T) + w_q.bias), \"w_q(q) doesn't equl to q*w_q^T + bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert torch.allclose(w_q(q), q @ w_q.weight.T), 'they are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If w = nn.Linear(d_model, d_model, bias=False) then they will be the same\n",
    "w_test = nn.Linear(d_model, d_model, bias=False)\n",
    "assert torch.allclose(w_test(q), q @ w_test.weight.T), 'they are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = w_q(q)\n",
    "key = w_k(k)\n",
    "value = w_v(v)\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 2, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the batch size and seq_len, decompose the matrix into smaller matrix\n",
    "# so we can give each small matrix different head\n",
    "# later, we can perform independent attention calculations for each head\n",
    "query.view(query.shape[0], query.shape[1], h, d_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The reason for using (batch_size, h, seq_len, d_k) instead of (batch_size, seq_len, h, d_k) is that:\n",
    "\n",
    "The attention mechanism operates independently across heads.\n",
    "Each head will perform self-attention on its own set of d_k-dimensional vectors.\n",
    "The typical implementation of multi-head attention expects the shape (batch_size, h, seq_len, d_k).\n",
    "When performing matrix multiplications (like query @ key.T), we want to apply attention per head.\n",
    "This format is easier for batched computations in PyTorch and TensorFlow.\n",
    "\"\"\"\n",
    "\n",
    "query.view(query.shape[0], query.shape[1], h, d_k).transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.view(query.shape[0], query.shape[1], h, d_k).transpose(1, 2)\n",
    "key = key.view(key.shape[0], key.shape[1], h, d_k).transpose(1, 2)\n",
    "value = value.view(value.shape[0], value.shape[1], h, d_k).transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0384, -0.5174, -0.1906, -1.4137,  0.4905],\n",
       "          [ 0.1017, -0.7355, -0.2343, -1.2537,  0.5481],\n",
       "          [ 0.2470,  0.4901,  0.9263,  0.4525,  0.0202],\n",
       "          [ 0.2632,  0.6250,  0.1026,  1.2607, -0.6318]],\n",
       "\n",
       "         [[ 0.3002, -0.8318, -0.5829,  0.3977, -0.7254],\n",
       "          [ 0.2306,  0.3447, -0.1397,  1.2709,  0.5996],\n",
       "          [-1.1840, -0.2869, -0.7956,  0.4389, -0.6056],\n",
       "          [ 0.1156,  0.2512,  0.0633,  0.2033,  0.4111]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0212, -0.1808, -0.7642, -0.1178, -0.8553],\n",
       "          [ 0.4806,  0.9083,  0.0723, -0.5145,  0.0628],\n",
       "          [-0.4036,  0.3494,  1.2037,  0.2365,  1.2856],\n",
       "          [ 1.1092,  0.5124, -0.2235,  0.7103,  0.2428]],\n",
       "\n",
       "         [[-1.1845, -0.8019, -0.2041, -0.9412,  0.2140],\n",
       "          [-0.0064,  0.3211, -0.1502, -0.6479,  0.1054],\n",
       "          [ 0.8050,  0.1512, -0.3431, -0.3922, -1.0753],\n",
       "          [ 1.0954,  0.8639,  0.2860,  0.3669, -0.0735]]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0943,  0.0114,  0.0344, -0.1186,  0.0603],\n",
       "          [-0.5520, -0.1646, -0.1299, -0.2376, -0.0683],\n",
       "          [-0.4892, -0.2988, -0.2007, -0.1164, -0.1496],\n",
       "          [-1.0023, -0.1987, -0.3948, -0.7448,  0.0721],\n",
       "          [ 0.3091, -0.0122,  0.0511,  0.2615, -0.0621]],\n",
       "\n",
       "         [[-0.1094,  0.2777,  0.0222, -0.8329, -0.0671],\n",
       "          [-0.1156,  0.2997, -0.2060, -0.7361,  0.4796],\n",
       "          [-0.2014,  0.4486, -0.0907, -1.0593,  0.4324],\n",
       "          [ 0.2370, -0.3385, -0.0294,  0.8026, -0.3635],\n",
       "          [-0.1252,  0.3277, -0.2443, -0.9578,  0.4235]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7129,  0.1607,  0.4501,  0.2432, -0.0638],\n",
       "          [ 1.0623,  0.0538,  0.4733,  0.4917, -0.3434],\n",
       "          [-0.0287, -0.6762, -0.1958,  0.7193, -0.5443],\n",
       "          [-0.3231, -0.5690, -0.1879,  0.2875, -0.3528],\n",
       "          [ 0.0710, -0.8597, -0.1486,  0.9305, -0.7185]],\n",
       "\n",
       "         [[ 0.0904,  0.4654, -0.1059,  0.4597,  0.4722],\n",
       "          [-0.2340,  0.4198, -0.1431,  0.3983,  0.8403],\n",
       "          [-0.3912,  0.0726, -0.1842, -0.0606,  0.3571],\n",
       "          [-0.9765,  0.0116, -0.3315, -0.2510,  0.2802],\n",
       "          [-0.7910, -0.0403, -0.2219, -0.2017,  0.6355]]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score = (query @ key.transpose(-2 ,-1)) / math.sqrt(d_k)\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Dropout Applied:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def numpy_dropout(x, p=0.5):\n",
    "    \"\"\"Applies dropout using NumPy with probability p\"\"\"\n",
    "    keep_prob = 1 - p\n",
    "    mask = np.random.binomial(n=1, p=keep_prob, size=x.shape)  # Create Bernoulli mask\n",
    "    return (x * mask) / keep_prob  # Scale to maintain expectation\n",
    "\n",
    "# Example input matrix\n",
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Apply dropout with probability p = 0.5\n",
    "dropout_output = numpy_dropout(x, p=0.5)\n",
    "\n",
    "print(\"Input Tensor:\\n\", x)\n",
    "print(\"Dropout Applied:\\n\", dropout_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide by 1-p for maintaining the expectation\n",
    "\n",
    "test this by multiple runs as follows, we can see the value is nearly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value of Input Tensor: 3.5\n",
      "Expected Value After Dropout (Averaged over 10000 runs): 3.4600\n"
     ]
    }
   ],
   "source": [
    "def numpy_dropout(x, p=0.5):\n",
    "    \"\"\"Applies dropout using NumPy with probability p\"\"\"\n",
    "    keep_prob = 1 - p\n",
    "    mask = np.random.binomial(n=1, p=keep_prob, size=x.shape)  # Create Bernoulli mask\n",
    "    return (x * mask) / keep_prob  # Scale to maintain expectation\n",
    "\n",
    "# Example input matrix\n",
    "x = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Compute expectation of the input\n",
    "expected_input = np.mean(x)\n",
    "\n",
    "# Run dropout multiple times and compute mean expectation\n",
    "num_trials = 10000\n",
    "expected_dropout_values = [np.mean(numpy_dropout(x, p=0.5)) for _ in range(num_trials)]\n",
    "\n",
    "# Compute the overall expectation across trials\n",
    "expected_dropout = np.mean(expected_dropout_values)\n",
    "\n",
    "print(\"Expected Value of Input Tensor:\", expected_input)\n",
    "print(\"Expected Value After Dropout (Averaged over {} runs): {:.4f}\".format(num_trials, expected_dropout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.1 0.5 0.9]\n",
      "Bernoulli Samples: [0 1 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def numpy_bernoulli(probabilities):\n",
    "    \"\"\"Simulates torch.bernoulli using NumPy.\"\"\"\n",
    "    return np.random.binomial(n=3, p=probabilities)\n",
    "\n",
    "# Example probability tensor (same as in PyTorch example)\n",
    "probabilities = np.array([0.1, 0.5, 0.9])\n",
    "\n",
    "# Generate Bernoulli samples\n",
    "samples = numpy_bernoulli(probabilities)\n",
    "\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print(\"Bernoulli Samples:\", samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Token  ID\n",
      "0    hello   7\n",
      "1    [SOS]   2\n",
      "2        ,   4\n",
      "3     this  12\n",
      "4        a  10\n",
      "5     test   8\n",
      "6        .   5\n",
      "7    [EOS]   3\n",
      "8    [UNK]   0\n",
      "9        !   9\n",
      "10      is  11\n",
      "11  banana   6\n",
      "12   [PAD]   1\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from tokenizers.normalizers import Lowercase\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import pandas as pd\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"Hello world!\",\n",
    "    \"Hello ChatGPT!\",\n",
    "    \"This is a test sentence.\",\n",
    "    \"Hello, this is another test.\",\n",
    "    \"Test your tokenizer with a sample text.\",\n",
    "    \"Banana, banana, BANANA\"\n",
    "]\n",
    "\n",
    "# Initialize a WordLevel tokenizer\n",
    "tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\"))\n",
    "\n",
    "# Set normalization (lowercasing)\n",
    "tokenizer.normalizer = Lowercase()\n",
    "\n",
    "# Set pre-tokenizer (whitespace splitting)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Trainer with min_frequency=2\n",
    "trainer = trainers.WordLevelTrainer(\n",
    "    min_frequency=2,\n",
    "    special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"]\n",
    ")\n",
    "\n",
    "# Train tokenizer\n",
    "tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "vocab_df = pd.DataFrame(vocab.items(), columns=[\"Token\", \"ID\"])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(vocab_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', '[UNK]', '!'],\n",
       " ['hello', '[UNK]', '!'],\n",
       " ['this', 'is', 'a', 'test', '[UNK]', '.'],\n",
       " ['hello', ',', 'this', 'is', '[UNK]', 'test', '.'],\n",
       " ['test', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '.'],\n",
       " ['banana', ',', 'banana', ',', 'banana']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [tokenizer.encode(sentence).tokens for sentence in corpus]\n",
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " '[UNK]',\n",
       " '!',\n",
       " 'hello',\n",
       " '[UNK]',\n",
       " '!',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " '[UNK]',\n",
       " '.',\n",
       " 'hello',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " '[UNK]',\n",
       " 'test',\n",
       " '.',\n",
       " 'test',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'a',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '.',\n",
       " 'banana',\n",
       " ',',\n",
       " 'banana',\n",
       " ',',\n",
       " 'banana']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the list of tokenized words\n",
    "flat_tokenized_words = [word for sentence in tokenized_corpus for word in sentence]\n",
    "flat_tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>banana</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token  Count\n",
       "0   hello      3\n",
       "1   [UNK]      9\n",
       "2       !      2\n",
       "3    this      2\n",
       "4      is      2\n",
       "5       a      2\n",
       "6    test      3\n",
       "7       .      3\n",
       "8       ,      3\n",
       "9  banana      3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each word in the vocabulary\n",
    "word_counts = Counter(flat_tokenized_words)\n",
    "word_count_df = pd.DataFrame(word_counts.items(), columns=[\"Token\", \"Count\"])\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  101, 2009, 2003, 1037, 2204, 2154,  102,    1,    2,    2,    2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tokens\n",
    "sos_token = torch.tensor([0])  # Start of Sequence <SOS>\n",
    "eos_token = torch.tensor([1])  # End of Sequence <EOS>\n",
    "pad_token = 2                  # Padding token\n",
    "\n",
    "# Example encoded tokens\n",
    "encoded_input_tokens = torch.tensor([101, 2009, 2003, 1037, 2204, 2154, 102])  # Main sequence\n",
    "encoded_num_padding_tokens = 3  # Number of padding tokens\n",
    "\n",
    "# Construct the encoded input using torch.cat()\n",
    "encoded_input = torch.cat([\n",
    "    sos_token,  \n",
    "    encoded_input_tokens,  \n",
    "    eos_token,  \n",
    "    torch.tensor([pad_token] * encoded_num_padding_tokens, dtype=torch.int64)\n",
    "])\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_input != pad_token).unsqueeze(0).unsqueeze(0).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a is decoded_input, so there is no eos\n",
    "\"\"\"\n",
    "decoder_input = torch.tensor([0, 12, 13, 2 , 2]) # the real input is 2: 0 is SOS, 2 is pad\n",
    "# b = torch.tensor([2])\n",
    "(decoder_input != pad_token).int() # False = 1: means the input rather thant pad token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build causal_mask with torch.ones\n",
    "causal_mask = torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1)\n",
    "\n",
    "# Use '&' to make the causal mask align with the length of the input sentence\n",
    "(decoder_input != pad_token).int() & (causal_mask == 0).type(torch.int) # Convert the 1 to 0, 0 to 1: align with the (a != b).int(), 1 means the real input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, num_samples=5, seq_len=6, pad_token=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.seq_len = seq_len\n",
    "        self.pad_token = pad_token\n",
    "        \n",
    "        # Fake tokenized sentences with different lengths\n",
    "        self.data = [\n",
    "            [101, 7592, 2088, 102],  # \"Hello world\"\n",
    "            [2054, 2024, 2017, 102],  # \"How are you?\"\n",
    "            [1045, 2572, 2986, 102],  # \"I am fine\"\n",
    "            [2748, 102],  # \"Yes\"\n",
    "            [2204, 2872, 102]  # \"Good morning\"\n",
    "        ]\n",
    "        \n",
    "        # Padding each sequence to `seq_len`\n",
    "        for i in range(len(self.data)):\n",
    "            self.data[i] += [self.pad_token] * (self.seq_len - len(self.data[i]))  # Padding\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Simulated encoder input (source sentence) and decoder input (target sentence)\n",
    "        encoded_input = torch.tensor(self.data[idx], dtype=torch.int64)  # (seq_len)\n",
    "        decoded_input = torch.tensor(self.data[idx], dtype=torch.int64)  # (seq_len)\n",
    "        \n",
    "        # Create masks\n",
    "        encoder_mask = (encoded_input != self.pad_token).unsqueeze(0).unsqueeze(0).int()  # (1, 1, seq_len)\n",
    "        decoder_mask = (decoded_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & self.causal_mask(decoded_input.size(0))  # (1, seq_len, seq_len)\n",
    "        \n",
    "        return {\n",
    "            \"encoder_input\": encoded_input,  # (seq_len)\n",
    "            \"decoder_input\": decoded_input,  # (seq_len)\n",
    "            \"encoder_mask\": encoder_mask,  # (1, 1, seq_len)\n",
    "            \"decoder_mask\": decoder_mask,  # (1, seq_len, seq_len)\n",
    "            \"label\": decoded_input,  # (seq_len)\n",
    "        }\n",
    "    \n",
    "    def causal_mask(self, size):\n",
    "        \"\"\" Generate a causal mask for the decoder to prevent attending future tokens \"\"\"\n",
    "        mask = torch.tril(torch.ones((size, size), dtype=torch.int))  # Lower triangular matrix\n",
    "        return mask.unsqueeze(0)  # (1, seq_len, seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the tensor before calculating loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain the shape transformation in the following:\n",
    "\n",
    "```\n",
    "(batch_size, seq_len, tgt_vocab_size) -> (batch_size * seq_len, tgt_vocab_size)  \n",
    "loss = loss_fn(project_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape of the loss function, CrossEntroyLoss, is: (N, C):\n",
    "- N is the number of samples (each token in this case).\n",
    "- C is the number of classes (vocabulary size in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output shape of project_layer is: (batch_size, seq_len, tgt_vocab_size).  \n",
    "example is following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.1, 0.2, 0.3, 0.1, 0.3],\n",
       "  [0.5, 0.2, 0.1, 0.1, 0.1],\n",
       "  [0.2, 0.3, 0.1, 0.3, 0.1]],\n",
       " [[0.3, 0.1, 0.2, 0.2, 0.2],\n",
       "  [0.4, 0.1, 0.1, 0.2, 0.2],\n",
       "  [0.1, 0.3, 0.2, 0.2, 0.2]]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[   \n",
    "    # three words(or tokens, actually) in the sentence 1\n",
    "    [[0.1, 0.2, 0.3, 0.1, 0.3],  # Token 1, Sentence 1\n",
    "     [0.5, 0.2, 0.1, 0.1, 0.1],  # Token 2, Sentence 1\n",
    "     [0.2, 0.3, 0.1, 0.3, 0.1]], # Token 3, Sentence 1\n",
    "\n",
    "    # sentence 2\n",
    "    [[0.3, 0.1, 0.2, 0.2, 0.2],  # Token 1, Sentence 2\n",
    "     [0.4, 0.1, 0.1, 0.2, 0.2],  # Token 2, Sentence 2\n",
    "     [0.1, 0.3, 0.2, 0.2, 0.2]]  # Token 3, Sentence 2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reshape to batch_size * seq_len, tgt_vocab_size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.1, 0.2, 0.3, 0.1, 0.3],\n",
       " [0.5, 0.2, 0.1, 0.1, 0.1],\n",
       " [0.2, 0.3, 0.1, 0.3, 0.1],\n",
       " [0.3, 0.1, 0.2, 0.2, 0.2],\n",
       " [0.4, 0.1, 0.1, 0.2, 0.2],\n",
       " [0.1, 0.3, 0.2, 0.2, 0.2]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    [0.1, 0.2, 0.3, 0.1, 0.3],  # Token 1, Sentence 1\n",
    "    [0.5, 0.2, 0.1, 0.1, 0.1],  # Token 2, Sentence 1\n",
    "    [0.2, 0.3, 0.1, 0.3, 0.1],  # Token 3, Sentence 1\n",
    "    [0.3, 0.1, 0.2, 0.2, 0.2],  # Token 1, Sentence 2\n",
    "    [0.4, 0.1, 0.1, 0.2, 0.2],  # Token 2, Sentence 2\n",
    "    [0.1, 0.3, 0.2, 0.2, 0.2]   # Token 3, Sentence 2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor([\n",
    "    [2, 0, 1],  # Ground-truth token indices for Sentence 1 (each value represents the correct class index for the corresponding token)\n",
    "    [4, 3, 1]   # Ground-truth token indices for Sentence 2\n",
    "])  # Shape: (2, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 4, 3, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.tensor v.s. torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.2196e-41, 1.8980e+01])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(2) # 2 is treated as a shape, not a value, so it creates a tensor of shape (2,) with randomly initialized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(2).requires_grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
