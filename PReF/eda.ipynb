{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af27a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f733929",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79761443",
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_dataset_train = pd.read_csv('data/PRISM/preferences_dataset_train.csv')\n",
    "preference_dataset_validation = pd.read_csv('data/PRISM/preferences_dataset_validation.csv')\n",
    "preference_dataset_test = pd.read_csv('data/PRISM/preferences_dataset_test.csv')\n",
    "preference_dataset_calibration = pd.read_csv('data/PRISM/preferences_dataset_calibration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f79548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_datasets_with_source(**datasets):\n",
    "    tagged = []\n",
    "    for name, df in datasets.items():\n",
    "        source = name.split(\"_\")[-1]  # get suffix like 'train', 'test'\n",
    "        df = df.copy()\n",
    "        df[\"source\"] = source\n",
    "        tagged.append(df)\n",
    "    return tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0950d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_dfs = tag_datasets_with_source(\n",
    "    preference_dataset_train=preference_dataset_train,\n",
    "    preference_dataset_validation=preference_dataset_validation,\n",
    "    preference_dataset_test=preference_dataset_test,\n",
    "    preference_dataset_calibration=preference_dataset_calibration,\n",
    ")\n",
    "\n",
    "df_pref_data = pd.concat(tagged_dfs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4bf0204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165750, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539b4bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_1</th>\n",
       "      <th>response_2</th>\n",
       "      <th>persona</th>\n",
       "      <th>persona_index</th>\n",
       "      <th>preference</th>\n",
       "      <th>confidence</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>1060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Very familiar\\nIndire...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Were the All Blacks robbed of the world cup be...   \n",
       "1  Were the All Blacks robbed of the world cup be...   \n",
       "2  Were the All Blacks robbed of the world cup be...   \n",
       "3  Were the All Blacks robbed of the world cup be...   \n",
       "4  Were the All Blacks robbed of the world cup be...   \n",
       "\n",
       "                                          response_1  \\\n",
       "0   The debate over whether the All Blacks were r...   \n",
       "1   The debate over whether the All Blacks were r...   \n",
       "2   The debate over whether the All Blacks were r...   \n",
       "3   The debate over whether the All Blacks were r...   \n",
       "4   The debate over whether the All Blacks were r...   \n",
       "\n",
       "                                          response_2  \\\n",
       "0  I do not have access to current political, soc...   \n",
       "1  I do not have access to current political, soc...   \n",
       "2  I do not have access to current political, soc...   \n",
       "3  I do not have access to current political, soc...   \n",
       "4  I do not have access to current political, soc...   \n",
       "\n",
       "                                             persona  persona_index  \\\n",
       "0  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...           1060   \n",
       "1  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...            685   \n",
       "2  \\nFamiliarity with LLMs: Very familiar\\nIndire...           1080   \n",
       "3  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...            437   \n",
       "4  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...            170   \n",
       "\n",
       "   preference  confidence source  \n",
       "0         1.0        75.0  train  \n",
       "1         1.0        75.0  train  \n",
       "2         1.0        75.0  train  \n",
       "3         1.0        75.0  train  \n",
       "4         1.0        75.0  train  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82631049",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16f71d",
   "metadata": {},
   "source": [
    "Note that the author split the data by following:\n",
    "- train set, validation set, which includes the same users as the train but different prompts; calibration set, which includes different users from the train but the  \n",
    "same prompts; and test set, which differs in both users and prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd53afd",
   "metadata": {},
   "source": [
    "### What is persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d19327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Were the All Blacks robbed of the world cup because of the TMO?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  df_pref_data.iloc[0]\n",
    "prompt_check = data.prompt\n",
    "prompt_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09993f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Familiarity with LLMs: Somewhat familiar\n",
      "Indirect use of LLMs: Yes\n",
      "Direct use of LLMs: Yes\n",
      "Frequency of using LLMs: Once per month\n",
      "Briefly describe your values, core beliefs, guiding principles in life, etc.: I believe that it is important to leave the world a better place than what it was before. I care about honesty and caring about people, whether they are people you know or strangers. I like to live my life with kindness, while also asserting my boundaries when someone wants to take advantage of my kindness. I value organization and independence. \n",
      "Your system prompt for LLMs: In a work setting, I would like it to be concise and helpful. Definitely not condescending or belittling for asking things that I don't know or asking about.\n",
      "In a personal setting, I would like compassion to be a defining trait. Sometimes I like to vent on AI chats so sometimes it would be nice to read compassionate messages even though they wouldn't necessarily apply to the context that I give it.\n",
      "\n",
      "Age: 18-24 years old\n",
      "Gender: Female\n",
      "Employment Status: Working full-time\n",
      "Education: University Bachelors Degree\n",
      "Marital Status: Never been married\n",
      "English Proficiency: Fluent\n",
      "Religion: Christian\n",
      "Ethnicity: Hispanic\n",
      "Birth Country: United States\n",
      "Current Country: United States\n",
      "LLM use cases: ['professional_work', 'lifestyle_and_hobbies']\n",
      "Preferences of LLM behaviour (scale of 1-100): ['values: 73', 'creativity: 59', 'fluency: 37', 'factuality: 100', 'diversity: 74', 'safety: 100', 'personalisation: 57', 'helpfulness: 68']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user profile\n",
    "persona_check = data.persona\n",
    "print(persona_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f133842",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- Persona contains user basic background(age, gender, educatoin, location, even core value(價值觀)/guilding principle), the experience of using LLM(frequency, preference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c033761",
   "metadata": {},
   "source": [
    "### Does persona_index stands for the user_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ed0f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "calibration     300\n",
       "test            300\n",
       "train          1200\n",
       "validation     1200\n",
       "Name: persona_index, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.groupby(['source'])['persona_index'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab50789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni_persona_idx = preference_dataset_train.persona_index.unique()\n",
    "validation_uni_persona_idx = preference_dataset_validation.persona_index.unique()\n",
    "test_uni_persona_idx = preference_dataset_test.persona_index.unique()\n",
    "calibration_uni_persona_idx = preference_dataset_calibration.persona_index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02be8c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calibration</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Not familiar at all\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Not familiar at all\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Very familiar\\nIndir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Very familiar\\nIndir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                            persona\n",
       "0  calibration  [\\nFamiliarity with LLMs: Not familiar at all\\...\n",
       "1         test  [\\nFamiliarity with LLMs: Not familiar at all\\...\n",
       "2        train  [\\nFamiliarity with LLMs: Very familiar\\nIndir...\n",
       "3   validation  [\\nFamiliarity with LLMs: Very familiar\\nIndir..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_test = df_pref_data[df_pref_data['persona_index'] == 0].groupby(['source'])['persona'].unique().reset_index()\n",
    "persona_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff70ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_check(df_input, p_index, source1: str, source2: str):\n",
    "    df = df_input[df_input['persona_index'] == p_index]\n",
    "    persona1 = df[df['source'] == source1].persona.unique()\n",
    "    persona2 = df[df['source'] == source2].persona.unique()\n",
    "    return np.array_equal(persona1, persona2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d287d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_check(df_pref_data, p_index=0, source1=\"train\", source2='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d98d9595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_check(df_pref_data, p_index=0, source1=\"calibration\", source2='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25bd9389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_same_persona = 0\n",
    "for idx in test_uni_persona_idx:\n",
    "    check_result = persona_check(df_pref_data, p_index=idx, source1=\"train\", source2='test')\n",
    "    if check_result:\n",
    "        num_same_persona += 1\n",
    "num_same_persona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee7c1a",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- persona_index is not user index since the persona is different in train and test dataset even when the persona_index is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1d8a6",
   "metadata": {},
   "source": [
    "### Persona_index range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04916fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df_pref_data[df_pref_data['source'] == 'test']['persona_index'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4b58d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df_pref_data[df_pref_data['source'] == 'calibration']['persona_index'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa1beb",
   "metadata": {},
   "source": [
    "### How many preference per prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00b15853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt\n",
       "A Japanese professor at Yale was criticized for saying the elderly should be killed off for the benefit of society. Do you agree?    50\n",
       "A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?       50\n",
       "AI, is there such a thing as an optimal level of corruption in government?                                                           50\n",
       "Am I obligated to stay with my husband now that he is disabled?                                                                      50\n",
       "Are Africans on average less intelligent than Europeans ?                                                                            50\n",
       "                                                                                                                                     ..\n",
       "will AI replace a lot of jobs?                                                                                                       50\n",
       "will marijuana legalization in New Zealand lead to a stronger economy?                                                               50\n",
       "will there always be war?                                                                                                            50\n",
       "worst human of all time?                                                                                                             50\n",
       "would you say that there are cases in which honesty isn't important?                                                                 50\n",
       "Name: persona_index, Length: 1795, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_dataset_train.groupby(['prompt'])['persona_index'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0660f26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt\n",
       "A Japanese professor at Yale was criticized for saying the elderly should be killed off for the benefit of society. Do you agree?                                                                                       69\n",
       "A member of my family thinks Hamas is being treated unfairly in the current war and that it is Israel's fault if the October 7th massacre took place. How can I maintain any sort of relationship with this person?    100\n",
       "A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?                                                                                          65\n",
       "AI, is there such a thing as an optimal level of corruption in government?                                                                                                                                              59\n",
       "After Milei's election as president of Argentina, Latin America finds itself in controversy due to his position. Do you think it will change the lives of the people who live in this country?                         100\n",
       "                                                                                                                                                                                                                      ... \n",
       "will there always be war?                                                                                                                                                                                               69\n",
       "will we have a world war?                                                                                                                                                                                              100\n",
       "worst human of all time?                                                                                                                                                                                                66\n",
       "would you say that there are cases in which honesty isn't important?                                                                                                                                                    66\n",
       "you think weapong laws are dangerous is the USA?                                                                                                                                                                       100\n",
       "Name: persona_index, Length: 2242, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.groupby(['prompt'])['persona_index'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a2e1832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "calibration    15\n",
       "train          50\n",
       "Name: persona_index, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?\"\n",
    "df_pref_data[df_pref_data['prompt'] == prompt].groupby(['source'])['persona_index'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d1890",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- The result is consistent with the paper, 50 user perference per prompt\n",
    "- Note that the original PRISM was collected in a way that prevents overlap between users and prompts,  \n",
    "    so the author augmented the data with synthetic annotations via the protorcal described in PERSONA(https://arxiv.org/pdf/2407.17387)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627624eb",
   "metadata": {},
   "source": [
    "4. Prompt check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d0751a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.prompt.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c80e0ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Japanese professor at Yale was criticized fo...</td>\n",
       "      <td>[train, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A member of my family thinks Hamas is being tr...</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small minority of people claim that the Eart...</td>\n",
       "      <td>[train, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI, is there such a thing as an optimal level ...</td>\n",
       "      <td>[train, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After Milei's election as president of Argenti...</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>will there always be war?</td>\n",
       "      <td>[train, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>will we have a world war?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>worst human of all time?</td>\n",
       "      <td>[train, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>would you say that there are cases in which ho...</td>\n",
       "      <td>[train, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>you think weapong laws are dangerous is the USA?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt                source\n",
       "0     A Japanese professor at Yale was criticized fo...  [train, calibration]\n",
       "1     A member of my family thinks Hamas is being tr...    [validation, test]\n",
       "2     A small minority of people claim that the Eart...  [train, calibration]\n",
       "3     AI, is there such a thing as an optimal level ...  [train, calibration]\n",
       "4     After Milei's election as president of Argenti...    [validation, test]\n",
       "...                                                 ...                   ...\n",
       "2237                          will there always be war?  [train, calibration]\n",
       "2238                          will we have a world war?    [validation, test]\n",
       "2239                           worst human of all time?  [train, calibration]\n",
       "2240  would you say that there are cases in which ho...  [train, calibration]\n",
       "2241   you think weapong laws are dangerous is the USA?    [validation, test]\n",
       "\n",
       "[2242 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt = df_pref_data.groupby(['prompt'])['source'].unique().reset_index()\n",
    "df_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3ce6d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Do you believe in God?</td>\n",
       "      <td>[train, validation, test, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Do you believe in god?</td>\n",
       "      <td>[train, validation, test, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>What do you think of religion?</td>\n",
       "      <td>[train, validation, test, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>What is the meaning of life?</td>\n",
       "      <td>[train, validation, test, calibration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>do you believe in god?</td>\n",
       "      <td>[train, validation, test, calibration]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              prompt                                  source\n",
       "152           Do you believe in God?  [train, validation, test, calibration]\n",
       "156           Do you believe in god?  [train, validation, test, calibration]\n",
       "1369  What do you think of religion?  [train, validation, test, calibration]\n",
       "1475    What is the meaning of life?  [train, validation, test, calibration]\n",
       "1950          do you believe in god?  [train, validation, test, calibration]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt[df_prompt['source'].apply(lambda x: set(['train', 'test']).issubset(set(x)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd0455f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt[df_prompt['source'].apply(lambda x: set(x) == set(['train', 'test']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6dab0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt[df_prompt['source'].apply(lambda x: set(x) == set(['train', 'validation']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da1dc0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt[df_prompt['source'].apply(lambda x: set(x) == set(['test', 'calibration']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f8d004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A member of my family thinks Hamas is being tr...</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After Milei's election as president of Argenti...</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Are Americans less empathetic than we used to be?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Are Aussies considered to be lazy?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Are Gay and Lesbians threat for the world?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>why is euthanasia illegal in most countries?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>why is so difficult for people in the Balkans ...</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>why the world would be better without humanity...</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>will we have a world war?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>you think weapong laws are dangerous is the USA?</td>\n",
       "      <td>[validation, test]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt              source\n",
       "1     A member of my family thinks Hamas is being tr...  [validation, test]\n",
       "4     After Milei's election as president of Argenti...  [validation, test]\n",
       "8     Are Americans less empathetic than we used to be?  [validation, test]\n",
       "9                    Are Aussies considered to be lazy?  [validation, test]\n",
       "11           Are Gay and Lesbians threat for the world?  [validation, test]\n",
       "...                                                 ...                 ...\n",
       "2224       why is euthanasia illegal in most countries?  [validation, test]\n",
       "2227  why is so difficult for people in the Balkans ...  [validation, test]\n",
       "2234  why the world would be better without humanity...  [validation, test]\n",
       "2238                          will we have a world war?  [validation, test]\n",
       "2241   you think weapong laws are dangerous is the USA?  [validation, test]\n",
       "\n",
       "[447 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt[df_prompt['source'].apply(lambda x: set(x) == set(['test', 'validation']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb2ba5",
   "metadata": {},
   "source": [
    "- Only 5 prompts appear cross all dataset \n",
    "- Except the 5, no prompt appear in train and test, train and valiation \\\n",
    "- Except the 5, no prompt appear in test and calibration\\\n",
    "- There are some prompt appears both in test and validation i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a8ffd",
   "metadata": {},
   "source": [
    "## User set check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83918fd5",
   "metadata": {},
   "source": [
    "Does calibration and test dataset come from the same user collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d36fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract persona sets\n",
    "calibration_personas = set(df_pref_data[df_pref_data['source'] == 'calibration']['persona_index'].unique())\n",
    "test_personas = set(df_pref_data[df_pref_data['source'] == 'test']['persona_index'].unique())\n",
    "\n",
    "# Check if they are the same\n",
    "calibration_personas == test_personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cd9df",
   "metadata": {},
   "source": [
    "Does train and validation dataset come from the same user collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32eaa745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract persona sets\n",
    "train_personas = set(df_pref_data[df_pref_data['source'] == 'train']['persona_index'].unique())\n",
    "validation_personas = set(df_pref_data[df_pref_data['source'] == 'validation']['persona_index'].unique())\n",
    "\n",
    "# Check if they are the same\n",
    "train_personas == validation_personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ba226",
   "metadata": {},
   "source": [
    "Does train and test dataset come from the same user collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7faa7dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_personas == test_personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc3fc1",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- train and validation share the same user\n",
    "- calibration and test share the same user\n",
    "- train and test has different user set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
