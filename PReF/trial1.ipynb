{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af27a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f733929",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9b8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\TWCC752671\\\\Sean\\\\git\\\\MLAlgoFromScratch\\\\PReF'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79761443",
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_dataset_train = pd.read_csv('data/PRISM/preferences_dataset_train.csv')\n",
    "preference_dataset_validation = pd.read_csv('data/PRISM/preferences_dataset_validation.csv')\n",
    "preference_dataset_test = pd.read_csv('data/PRISM/preferences_dataset_test.csv')\n",
    "preference_dataset_calibration = pd.read_csv('data/PRISM/preferences_dataset_calibration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4f79548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_datasets_with_source(**datasets):\n",
    "    tagged = []\n",
    "    for name, df in datasets.items():\n",
    "        source = name.split(\"_\")[-1]  # get suffix like 'train', 'test'\n",
    "        df = df.copy()\n",
    "        df[\"source\"] = source\n",
    "        tagged.append(df)\n",
    "    return tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0950d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_dfs = tag_datasets_with_source(\n",
    "    preference_dataset_train=preference_dataset_train,\n",
    "    preference_dataset_validation=preference_dataset_validation,\n",
    "    preference_dataset_test=preference_dataset_test,\n",
    "    preference_dataset_calibration=preference_dataset_calibration,\n",
    ")\n",
    "\n",
    "df_pref_data = pd.concat(tagged_dfs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4bf0204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165750, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "539b4bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_1</th>\n",
       "      <th>response_2</th>\n",
       "      <th>persona</th>\n",
       "      <th>persona_index</th>\n",
       "      <th>preference</th>\n",
       "      <th>confidence</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>1060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Very familiar\\nIndire...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were the All Blacks robbed of the world cup be...</td>\n",
       "      <td>The debate over whether the All Blacks were r...</td>\n",
       "      <td>I do not have access to current political, soc...</td>\n",
       "      <td>\\nFamiliarity with LLMs: Somewhat familiar\\nIn...</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Were the All Blacks robbed of the world cup be...   \n",
       "1  Were the All Blacks robbed of the world cup be...   \n",
       "2  Were the All Blacks robbed of the world cup be...   \n",
       "3  Were the All Blacks robbed of the world cup be...   \n",
       "4  Were the All Blacks robbed of the world cup be...   \n",
       "\n",
       "                                          response_1  \\\n",
       "0   The debate over whether the All Blacks were r...   \n",
       "1   The debate over whether the All Blacks were r...   \n",
       "2   The debate over whether the All Blacks were r...   \n",
       "3   The debate over whether the All Blacks were r...   \n",
       "4   The debate over whether the All Blacks were r...   \n",
       "\n",
       "                                          response_2  \\\n",
       "0  I do not have access to current political, soc...   \n",
       "1  I do not have access to current political, soc...   \n",
       "2  I do not have access to current political, soc...   \n",
       "3  I do not have access to current political, soc...   \n",
       "4  I do not have access to current political, soc...   \n",
       "\n",
       "                                             persona  persona_index  \\\n",
       "0  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...           1060   \n",
       "1  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...            685   \n",
       "2  \\nFamiliarity with LLMs: Very familiar\\nIndire...           1080   \n",
       "3  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...            437   \n",
       "4  \\nFamiliarity with LLMs: Somewhat familiar\\nIn...            170   \n",
       "\n",
       "   preference  confidence source  \n",
       "0         1.0        75.0  train  \n",
       "1         1.0        75.0  train  \n",
       "2         1.0        75.0  train  \n",
       "3         1.0        75.0  train  \n",
       "4         1.0        75.0  train  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82631049",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16f71d",
   "metadata": {},
   "source": [
    "Note that the author split the data by following:\n",
    "- train set, validation set, which includes the same users as the train but different prompts; calibration set, which includes different users from the train but the  \n",
    "same prompts; and test set, which differs in both users and prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd53afd",
   "metadata": {},
   "source": [
    "1. What is persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56d19327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Were the All Blacks robbed of the world cup because of the TMO?'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  df_pref_data.iloc[0]\n",
    "prompt_check = data.prompt\n",
    "prompt_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09993f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Familiarity with LLMs: Somewhat familiar\n",
      "Indirect use of LLMs: Yes\n",
      "Direct use of LLMs: Yes\n",
      "Frequency of using LLMs: Once per month\n",
      "Briefly describe your values, core beliefs, guiding principles in life, etc.: I believe that it is important to leave the world a better place than what it was before. I care about honesty and caring about people, whether they are people you know or strangers. I like to live my life with kindness, while also asserting my boundaries when someone wants to take advantage of my kindness. I value organization and independence. \n",
      "Your system prompt for LLMs: In a work setting, I would like it to be concise and helpful. Definitely not condescending or belittling for asking things that I don't know or asking about.\n",
      "In a personal setting, I would like compassion to be a defining trait. Sometimes I like to vent on AI chats so sometimes it would be nice to read compassionate messages even though they wouldn't necessarily apply to the context that I give it.\n",
      "\n",
      "Age: 18-24 years old\n",
      "Gender: Female\n",
      "Employment Status: Working full-time\n",
      "Education: University Bachelors Degree\n",
      "Marital Status: Never been married\n",
      "English Proficiency: Fluent\n",
      "Religion: Christian\n",
      "Ethnicity: Hispanic\n",
      "Birth Country: United States\n",
      "Current Country: United States\n",
      "LLM use cases: ['professional_work', 'lifestyle_and_hobbies']\n",
      "Preferences of LLM behaviour (scale of 1-100): ['values: 73', 'creativity: 59', 'fluency: 37', 'factuality: 100', 'diversity: 74', 'safety: 100', 'personalisation: 57', 'helpfulness: 68']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user profile\n",
    "persona_check = data.persona\n",
    "print(persona_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f133842",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- Persona contains user basic background(age, gender, educatoin, location, even core value(價值觀)/guilding principle), the experience of using LLM(frequency, preference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c033761",
   "metadata": {},
   "source": [
    "2. does persona_index stands for the user_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "250a2c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.persona_index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70ed0f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "calibration     300\n",
       "test            300\n",
       "train          1200\n",
       "validation     1200\n",
       "Name: persona_index, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.groupby(['source'])['persona_index'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9689c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             train  validation  test  calibration\n",
      "train         1200        1200   300          300\n",
      "validation    1200        1200   300          300\n",
      "test           300         300   300          300\n",
      "calibration    300         300   300          300\n"
     ]
    }
   ],
   "source": [
    "sources = df_pref_data['source'].unique()\n",
    "\n",
    "# Map each source to its unique persona_index\n",
    "source_to_personas = {\n",
    "    src: df_pref_data[df_pref_data['source'] == src]['persona_index'].unique()\n",
    "    for src in sources\n",
    "}\n",
    "\n",
    "# Create 2D overlap matrix\n",
    "overlap_matrix = pd.DataFrame(index=sources, columns=sources)\n",
    "\n",
    "for src1 in sources:\n",
    "    for src2 in sources:\n",
    "        overlap = np.intersect1d(source_to_personas[src1], source_to_personas[src2])\n",
    "        overlap_matrix.loc[src1, src2] = len(overlap)\n",
    "\n",
    "# Convert values to int\n",
    "overlap_matrix = overlap_matrix.astype(int)\n",
    "print(overlap_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab50789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uni_persona_idx = preference_dataset_train.persona_index.unique()\n",
    "validation_uni_persona_idx = preference_dataset_validation.persona_index.unique()\n",
    "test_uni_persona_idx = preference_dataset_test.persona_index.unique()\n",
    "calibration_uni_persona_idx = preference_dataset_calibration.persona_index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "02be8c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calibration</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Not familiar at all\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Not familiar at all\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Very familiar\\nIndir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation</td>\n",
       "      <td>[\\nFamiliarity with LLMs: Very familiar\\nIndir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                            persona\n",
       "0  calibration  [\\nFamiliarity with LLMs: Not familiar at all\\...\n",
       "1         test  [\\nFamiliarity with LLMs: Not familiar at all\\...\n",
       "2        train  [\\nFamiliarity with LLMs: Very familiar\\nIndir...\n",
       "3   validation  [\\nFamiliarity with LLMs: Very familiar\\nIndir..."
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_test = df_pref_data[df_pref_data['persona_index'] == 0].groupby(['source'])['persona'].unique().reset_index()\n",
    "persona_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bff70ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_check(df_input, p_index, source1: str, source2: str):\n",
    "    df = df_input[df_input['persona_index'] == p_index]\n",
    "    persona1 = df[df['source'] == source1].persona.unique()\n",
    "    persona2 = df[df['source'] == source2].persona.unique()\n",
    "    return np.array_equal(persona1, persona2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d287d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_check(df_pref_data, p_index=0, source1=\"train\", source2='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d98d9595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_check(df_pref_data, p_index=0, source1=\"calibration\", source2='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd9389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "for idx in test_uni_persona_idx:\n",
    "    persona_check(df_pref_data, p_index=idx, source1=\"train\", source2='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee7c1a",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- persona_index is not user index since the persona is different in train and test dataset even when the persona_index is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa1beb",
   "metadata": {},
   "source": [
    "3. How many preference per prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00b15853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt\n",
       "A Japanese professor at Yale was criticized for saying the elderly should be killed off for the benefit of society. Do you agree?    50\n",
       "A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?       50\n",
       "AI, is there such a thing as an optimal level of corruption in government?                                                           50\n",
       "Am I obligated to stay with my husband now that he is disabled?                                                                      50\n",
       "Are Africans on average less intelligent than Europeans ?                                                                            50\n",
       "                                                                                                                                     ..\n",
       "will AI replace a lot of jobs?                                                                                                       50\n",
       "will marijuana legalization in New Zealand lead to a stronger economy?                                                               50\n",
       "will there always be war?                                                                                                            50\n",
       "worst human of all time?                                                                                                             50\n",
       "would you say that there are cases in which honesty isn't important?                                                                 50\n",
       "Name: persona_index, Length: 1795, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_dataset_train.groupby(['prompt'])['persona_index'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0660f26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt\n",
       "A Japanese professor at Yale was criticized for saying the elderly should be killed off for the benefit of society. Do you agree?                                                                                       69\n",
       "A member of my family thinks Hamas is being treated unfairly in the current war and that it is Israel's fault if the October 7th massacre took place. How can I maintain any sort of relationship with this person?    100\n",
       "A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?                                                                                          65\n",
       "AI, is there such a thing as an optimal level of corruption in government?                                                                                                                                              59\n",
       "After Milei's election as president of Argentina, Latin America finds itself in controversy due to his position. Do you think it will change the lives of the people who live in this country?                         100\n",
       "                                                                                                                                                                                                                      ... \n",
       "will there always be war?                                                                                                                                                                                               69\n",
       "will we have a world war?                                                                                                                                                                                              100\n",
       "worst human of all time?                                                                                                                                                                                                66\n",
       "would you say that there are cases in which honesty isn't important?                                                                                                                                                    66\n",
       "you think weapong laws are dangerous is the USA?                                                                                                                                                                       100\n",
       "Name: persona_index, Length: 2242, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.groupby(['prompt'])['persona_index'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a2e1832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "calibration    15\n",
       "train          50\n",
       "Name: persona_index, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?\"\n",
    "df_pref_data[df_pref_data['prompt'] == prompt].groupby(['source'])['persona_index'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d1890",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- The result is consistent with the paper, 50 user perference per prompt\n",
    "- Note that the original PRISM was collected in a way that prevents overlap between users and prompts,  \n",
    "    so the author augmented the data with synthetic annotations via the protorcal described in PERSONA(https://arxiv.org/pdf/2407.17387)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627624eb",
   "metadata": {},
   "source": [
    "4. Prompt numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d0751a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.prompt.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c80e0ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt\n",
       "A Japanese professor at Yale was criticized for saying the elderly should be killed off for the benefit of society. Do you agree?                                                                                      [train, calibration]\n",
       "A member of my family thinks Hamas is being treated unfairly in the current war and that it is Israel's fault if the October 7th massacre took place. How can I maintain any sort of relationship with this person?      [validation, test]\n",
       "A small minority of people claim that the Earth is flat. What arguments can you provide in favor of the flat Earth hypothesis?                                                                                         [train, calibration]\n",
       "AI, is there such a thing as an optimal level of corruption in government?                                                                                                                                             [train, calibration]\n",
       "After Milei's election as president of Argentina, Latin America finds itself in controversy due to his position. Do you think it will change the lives of the people who live in this country?                           [validation, test]\n",
       "                                                                                                                                                                                                                               ...         \n",
       "will there always be war?                                                                                                                                                                                              [train, calibration]\n",
       "will we have a world war?                                                                                                                                                                                                [validation, test]\n",
       "worst human of all time?                                                                                                                                                                                               [train, calibration]\n",
       "would you say that there are cases in which honesty isn't important?                                                                                                                                                   [train, calibration]\n",
       "you think weapong laws are dangerous is the USA?                                                                                                                                                                         [validation, test]\n",
       "Name: source, Length: 2242, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pref_data.groupby(['prompt'])['source'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
